{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Profilis","text":"<p>A high\u2011performance, non\u2011blocking profiler for Python web applications.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Frameworks: Flask \u2705, FastAPI (planned v0.3.0), Sanic (planned v0.3.0)</li> <li>Databases: SQLAlchemy \u2705 (sync &amp; async), pyodbc (planned v0.2.0), MongoDB (planned v0.2.0), Neo4j (planned v0.2.0)</li> <li>UI: Built\u2011in, real-time dashboard \u2705</li> <li>Exporters: JSONL (rotating) \u2705, Console \u2705, Prometheus (planned v0.4.0), OTLP (planned v0.4.0)</li> <li>Performance: \u226415\u00b5s per event, 100K+ events/second</li> </ul>"},{"location":"#quick-start-flask","title":"Quick start (Flask)","text":"<pre><code>pip install profilis[flask,sqlalchemy]\n</code></pre> <pre><code>from flask import Flask\nfrom profilis.flask.adapter import ProfilisFlask\nfrom profilis.exporters.jsonl import JSONLExporter\nfrom profilis.core.async_collector import AsyncCollector\n\n# Setup exporter and collector\nexporter = JSONLExporter(dir=\"./logs\", rotate_bytes=1024*1024, rotate_secs=3600)\ncollector = AsyncCollector(exporter, queue_size=2048, batch_max=128, flush_interval=0.1)\n\n# Create Flask app and integrate Profilis\napp = Flask(__name__)\nprofilis = ProfilisFlask(\n    app,\n    collector=collector,\n    exclude_routes=[\"/health\", \"/metrics\"],\n    sample=1.0\n)\n\n@app.route('/health')\ndef ok():\n    return {'ok': True}\n\n# Visit /_profilis for the dashboard\n</code></pre>"},{"location":"#whats-new-in-v010","title":"What's New in v0.1.0","text":"<ul> <li>\u2705 Core Profiling Engine: AsyncCollector, Emitter, and runtime context</li> <li>\u2705 Flask Integration: Automatic request/response profiling with hooks</li> <li>\u2705 SQLAlchemy Instrumentation: Both sync and async engine support with query redaction</li> <li>\u2705 Built-in Dashboard: Real-time metrics and error tracking with authentication</li> <li>\u2705 JSONL Exporter: Rotating log files with configurable retention</li> <li>\u2705 Function Profiling: Decorator-based timing for sync/async functions with exception tracking</li> <li>\u2705 Performance Optimized: Non-blocking collection with configurable batching and drop-oldest policy</li> </ul>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>Installation - Complete installation guide and options</li> <li>Getting Started - Quick setup and basic usage</li> <li>Configuration - Tuning and customization</li> <li>Framework Adapters - Flask integration, FastAPI (planned)</li> <li>Database Support - SQLAlchemy integration</li> <li>Exporters - JSONL and Console exporters</li> <li>Architecture - System design and components</li> <li>UI Dashboard - Built-in monitoring interface</li> </ul>"},{"location":"adapters/fastapi/","title":"FastAPI Adapter","text":"<p>Note: FastAPI support is planned for v0.3.0. The current v0.1.0 release includes Flask integration and core profiling capabilities.</p>"},{"location":"adapters/fastapi/#current-status","title":"Current Status","text":"<p>FastAPI integration is not yet available in v0.1.0. The roadmap includes:</p> <ul> <li>v0.1.0 \u2014 Core + Flask + SQLAlchemy + UI \u2705</li> <li>v0.2.0 \u2014 pyodbc + Mongo + Neo4j</li> <li>v0.3.0 \u2014 ASGI (FastAPI/Sanic) \ud83d\udd04</li> <li>v0.4.0 \u2014 Sampling + Prometheus + Resilience</li> <li>v1.0.0 \u2014 Benchmarks + Docs + Release</li> </ul>"},{"location":"adapters/fastapi/#whats-available-now","title":"What's Available Now","text":"<p>While waiting for FastAPI support, you can use Profilis's core profiling capabilities with manual instrumentation:</p>"},{"location":"adapters/fastapi/#function-profiling","title":"Function Profiling","text":"<pre><code>from profilis.decorators.profile import profile_function\nfrom profilis.core.emitter import Emitter\nfrom profilis.exporters.jsonl import JSONLExporter\nfrom profilis.core.async_collector import AsyncCollector\n\n# Setup profiling\nexporter = JSONLExporter(dir=\"./logs\")\ncollector = AsyncCollector(exporter)\nemitter = Emitter(collector)\n\n@profile_function(emitter)\nasync def fastapi_handler():\n    \"\"\"Profile individual FastAPI handlers\"\"\"\n    # Your FastAPI logic here\n    pass\n</code></pre>"},{"location":"adapters/fastapi/#manual-request-profiling","title":"Manual Request Profiling","text":"<pre><code>from fastapi import FastAPI, Request\nfrom profilis.core.emitter import Emitter\nfrom profilis.exporters.jsonl import JSONLExporter\nfrom profilis.core.async_collector import AsyncCollector\nfrom profilis.runtime import use_span, span_id\nimport time\n\napp = FastAPI()\n\n# Setup Profilis\nexporter = JSONLExporter(dir=\"./logs\")\ncollector = AsyncCollector(exporter)\nemitter = Emitter(collector)\n\n@app.middleware(\"http\")\nasync def profilis_middleware(request: Request, call_next):\n    start_time = time.time_ns()\n\n    # Create trace context\n    with use_span(trace_id=span_id()):\n        try:\n            response = await call_next(request)\n            duration = time.time_ns() - start_time\n\n            # Emit request event\n            emitter.emit_req(\n                route=str(request.url.path),\n                status=response.status_code,\n                dur_ns=duration\n            )\n\n            return response\n        except Exception as e:\n            duration = time.time_ns() - start_time\n\n            # Emit error event\n            emitter.emit_req(\n                route=str(request.url.path),\n                status=500,\n                dur_ns=duration\n            )\n            raise\n</code></pre> <p>Note: This manual approach works but doesn't provide the same level of integration as the planned FastAPI adapter, which will include automatic route detection, better exception handling, and performance optimizations.</p>"},{"location":"adapters/fastapi/#planned-features-for-v030","title":"Planned Features for v0.3.0","text":"<p>The FastAPI adapter will include:</p> <ul> <li>Automatic Request Profiling: Middleware-based request/response timing</li> <li>ASGI Integration: Native ASGI middleware support</li> <li>Route Detection: Automatic route template identification</li> <li>Exception Handling: Built-in error tracking and reporting</li> <li>Performance Optimization: Minimal overhead for high-throughput APIs</li> </ul>"},{"location":"adapters/fastapi/#alternative-solutions","title":"Alternative Solutions","text":""},{"location":"adapters/fastapi/#use-flask-for-now","title":"Use Flask for Now","text":"<p>If you need immediate profiling, consider using Flask for the profiling layer:</p> <pre><code>from flask import Flask\nfrom profilis.flask.adapter import ProfilisFlask\nfrom profilis.exporters.jsonl import JSONLExporter\nfrom profilis.core.async_collector import AsyncCollector\n\n# Setup Profilis with Flask\nflask_app = Flask(__name__)\nexporter = JSONLExporter(dir=\"./logs\")\ncollector = AsyncCollector(exporter)\nprofilis = ProfilisFlask(flask_app, collector=collector)\n\n# Use the same collector for FastAPI manual profiling\n# (when FastAPI support is available)\n</code></pre>"},{"location":"adapters/fastapi/#manual-instrumentation","title":"Manual Instrumentation","text":"<p>For critical paths, use manual instrumentation:</p> <pre><code>from profilis.core.emitter import Emitter\nfrom profilis.runtime import use_span, span_id\n\n@app.get(\"/api/critical\")\nasync def critical_endpoint():\n    with use_span(trace_id=span_id()):\n        # Your critical logic here\n        result = await expensive_operation()\n\n        # Manual profiling\n        emitter.emit_fn(\"expensive_operation\", dur_ns=1000000)\n\n        return result\n</code></pre>"},{"location":"adapters/fastapi/#stay-updated","title":"Stay Updated","text":"<ul> <li>GitHub Issues: Track progress on FastAPI integration</li> <li>Roadmap: See docs/overview/roadmap.md for detailed planning</li> <li>Discussions: Join the conversation in GitHub Discussions</li> </ul>"},{"location":"adapters/fastapi/#related-documentation","title":"Related Documentation","text":"<ul> <li>Getting Started - Core Profilis usage</li> <li>Configuration - Tuning and customization</li> <li>Architecture - System design and components</li> <li>Exporters - Available output formats</li> </ul>"},{"location":"adapters/flask/","title":"Flask Adapter","text":"<p>The Flask adapter provides automatic request/response profiling with minimal code changes.</p>"},{"location":"adapters/flask/#quick-start","title":"Quick Start","text":"<pre><code>from flask import Flask\nfrom profilis.flask.adapter import ProfilisFlask\nfrom profilis.exporters.jsonl import JSONLExporter\nfrom profilis.core.async_collector import AsyncCollector\n\n# Setup exporter and collector\nexporter = JSONLExporter(dir=\"./logs\", rotate_bytes=1024*1024, rotate_secs=3600)\ncollector = AsyncCollector(exporter, queue_size=2048, batch_max=128, flush_interval=0.1)\n\n# Create Flask app\napp = Flask(__name__)\n\n# Integrate Profilis\nprofilis = ProfilisFlask(\n    app,\n    collector=collector,\n    exclude_routes=[\"/health\", \"/metrics\"],\n    sample=1.0  # 100% sampling\n)\n\n@app.route('/api/users')\ndef get_users():\n    return {\"users\": [\"alice\", \"bob\"]}\n\nif __name__ == \"__main__\":\n    app.run(debug=True)\n</code></pre>"},{"location":"adapters/flask/#features","title":"Features","text":""},{"location":"adapters/flask/#automatic-profiling","title":"Automatic Profiling","text":"<ul> <li>Request Timing: Measures request duration with microsecond precision</li> <li>Status Tracking: Records HTTP status codes and error conditions</li> <li>Route Detection: Automatically identifies route templates when available</li> <li>Exception Handling: Captures and records exceptions with stack traces</li> <li>Bytes In/Out: Tracks request/response sizes (best-effort)</li> </ul>"},{"location":"adapters/flask/#performance-optimized","title":"Performance Optimized","text":"<ul> <li>Non-blocking: All profiling happens asynchronously</li> <li>Sampling Support: Configurable sampling rates for production use</li> <li>Route Exclusion: Skip profiling for health checks and static assets</li> <li>Minimal Overhead: \u226415\u00b5s per request profiling cost</li> </ul>"},{"location":"adapters/flask/#configuration","title":"Configuration","text":""},{"location":"adapters/flask/#basic-configuration","title":"Basic Configuration","text":"<pre><code>profilis = ProfilisFlask(\n    app,\n    collector=collector,           # Required: AsyncCollector instance\n    exclude_routes=None,           # Optional: Routes to exclude\n    sample=1.0                     # Optional: Sampling rate (0.0-1.0)\n)\n</code></pre>"},{"location":"adapters/flask/#advanced-configuration","title":"Advanced Configuration","text":"<pre><code># Production configuration with sampling\nprofilis = ProfilisFlask(\n    app,\n    collector=collector,\n    exclude_routes=[\n        \"/health\",\n        \"/metrics\",\n        \"/_profilis\",  # Built-in dashboard\n        \"/static\",     # Static assets\n        \"/admin\"       # Admin routes\n    ],\n    sample=0.1  # 10% sampling in production\n)\n</code></pre>"},{"location":"adapters/flask/#what-gets-profiled","title":"What Gets Profiled","text":""},{"location":"adapters/flask/#request-events-req","title":"Request Events (REQ)","text":"<p>Each HTTP request generates a <code>REQ</code> event with:</p> <pre><code>{\n  \"ts_ns\": 1703123456789000000,\n  \"trace_id\": \"trace-abc123\",\n  \"span_id\": \"span-def456\",\n  \"kind\": \"REQ\",\n  \"route\": \"/api/users\",\n  \"status\": 200,\n  \"dur_ns\": 15000000,\n  \"bytes_in\": 1024,\n  \"bytes_out\": 2048\n}\n</code></pre> <p>Fields: - <code>ts_ns</code>: Timestamp in nanoseconds - <code>trace_id</code>: Unique trace identifier - <code>span_id</code>: Unique span identifier - <code>route</code>: Request route/path - <code>status</code>: HTTP status code - <code>dur_ns</code>: Request duration in nanoseconds - <code>bytes_in</code>: Request body size (if available) - <code>bytes_out</code>: Response body size (if available)</p>"},{"location":"adapters/flask/#exception-events-req_meta","title":"Exception Events (REQ_META)","text":"<p>When exceptions occur, additional metadata is recorded:</p> <pre><code>{\n  \"kind\": \"REQ_META\",\n  \"ts_ns\": 1703123456789000000,\n  \"trace_id\": \"trace-abc123\",\n  \"span_id\": \"span-def456\",\n  \"route\": \"/api/users\",\n  \"exception_type\": \"ValueError\",\n  \"exception_value\": \"Invalid user ID\",\n  \"traceback\": \"...\"\n}\n</code></pre>"},{"location":"adapters/flask/#integration-patterns","title":"Integration Patterns","text":""},{"location":"adapters/flask/#with-built-in-dashboard","title":"With Built-in Dashboard","text":"<pre><code>from profilis.flask.ui import make_ui_blueprint\nfrom profilis.core.stats import StatsStore\n\napp = Flask(__name__)\nstats = StatsStore()\n\n# Setup Profilis profiling\nprofilis = ProfilisFlask(app, collector=collector)\n\n# Add dashboard\nui_bp = make_ui_blueprint(stats, ui_prefix=\"/_profilis\")\napp.register_blueprint(ui_bp)\n\n# Visit /_profilis for real-time metrics\n</code></pre>"},{"location":"adapters/flask/#with-custom-exporters","title":"With Custom Exporters","text":"<pre><code>from profilis.exporters.console import ConsoleExporter\nfrom profilis.exporters.jsonl import JSONLExporter\n\n# Multiple exporters\nconsole_exporter = ConsoleExporter(pretty=True)\njsonl_exporter = JSONLExporter(dir=\"./logs\")\n\n# Use JSONL for production, console for development\nif app.debug:\n    collector = AsyncCollector(console_exporter)\nelse:\n    collector = AsyncCollector(jsonl_exporter)\n\nprofilis = ProfilisFlask(app, collector=collector)\n</code></pre>"},{"location":"adapters/flask/#with-database-instrumentation","title":"With Database Instrumentation","text":"<pre><code>from profilis.sqlalchemy.instrumentation import instrument_sqlalchemy\n\n# Instrument SQLAlchemy\ninstrument_sqlalchemy(engine, collector)\n\n# Flask adapter will automatically correlate request and database events\nprofilis = ProfilisFlask(app, collector=collector)\n</code></pre>"},{"location":"adapters/flask/#performance-considerations","title":"Performance Considerations","text":""},{"location":"adapters/flask/#sampling-strategies","title":"Sampling Strategies","text":"<pre><code># Development: 100% sampling\nprofilis = ProfilisFlask(app, collector=collector, sample=1.0)\n\n# Staging: 50% sampling\nprofilis = ProfilisFlask(app, collector=collector, sample=0.5)\n\n# Production: 10% sampling\nprofilis = ProfilisFlask(app, collector=collector, sample=0.1)\n\n# Critical endpoints: Always profile\nprofilis = ProfilisFlask(\n    app,\n    collector=collector,\n    exclude_routes=[\"/health\", \"/metrics\"],\n    sample=1.0  # 100% for critical paths\n)\n</code></pre>"},{"location":"adapters/flask/#route-exclusion","title":"Route Exclusion","text":"<pre><code># Exclude monitoring and static routes\nexclude_routes = [\n    \"/health\",           # Health checks\n    \"/metrics\",          # Metrics endpoints\n    \"/_profilis\",        # Built-in dashboard\n    \"/static\",           # Static assets\n    \"/admin\",            # Admin interface\n    \"/favicon.ico\"       # Browser requests\n]\n\nprofilis = ProfilisFlask(\n    app,\n    collector=collector,\n    exclude_routes=exclude_routes\n)\n</code></pre>"},{"location":"adapters/flask/#error-handling","title":"Error Handling","text":""},{"location":"adapters/flask/#exception-tracking","title":"Exception Tracking","text":"<p>The Flask adapter automatically captures exceptions:</p> <pre><code>@app.route('/api/users/&lt;user_id&gt;')\ndef get_user(user_id):\n    try:\n        user = database.get_user(user_id)\n        if not user:\n            raise ValueError(f\"User {user_id} not found\")\n        return user\n    except ValueError as e:\n        # This exception will be automatically recorded\n        raise\n    except Exception as e:\n        # All exceptions are captured\n        app.logger.error(f\"Unexpected error: {e}\")\n        raise\n</code></pre>"},{"location":"adapters/flask/#custom-error-handling","title":"Custom Error Handling","text":"<pre><code>from profilis.core.emitter import Emitter\n\n@app.errorhandler(404)\ndef not_found(error):\n    # Custom error handling with profiling\n    emitter = Emitter(collector)\n    emitter.emit_req(request.path, 404, dur_ns=0)\n    return {\"error\": \"Not found\"}, 404\n</code></pre>"},{"location":"adapters/flask/#testing","title":"Testing","text":""},{"location":"adapters/flask/#unit-testing","title":"Unit Testing","text":"<pre><code>import pytest\nfrom flask import Flask\nfrom profilis.flask.adapter import ProfilisFlask\nfrom profilis.exporters.console import ConsoleExporter\n\n@pytest.fixture\ndef app():\n    app = Flask(__name__)\n\n    # Use console exporter for testing\n    exporter = ConsoleExporter(pretty=False)\n    collector = AsyncCollector(exporter, queue_size=128, flush_interval=0.01)\n\n    profilis = ProfilisFlask(app, collector=collector)\n    return app\n\ndef test_user_endpoint(app, client):\n    response = client.get('/api/users')\n    assert response.status_code == 200\n</code></pre>"},{"location":"adapters/flask/#integration-testing","title":"Integration Testing","text":"<pre><code>def test_profiling_integration(app, client):\n    # Make requests\n    client.get('/api/users')\n    client.get('/api/users/1')\n\n    # Verify profiling data\n    # (Implementation depends on your testing strategy)\n</code></pre>"},{"location":"adapters/flask/#troubleshooting","title":"Troubleshooting","text":""},{"location":"adapters/flask/#common-issues","title":"Common Issues","text":"<ol> <li>Import Errors: Ensure you're using <code>profilis.flask.adapter.ProfilisFlask</code></li> <li>Missing Collector: Always provide an AsyncCollector instance</li> <li>Route Conflicts: Check for conflicts with built-in dashboard routes</li> <li>Performance Impact: Use sampling in production to reduce overhead</li> </ol>"},{"location":"adapters/flask/#debug-mode","title":"Debug Mode","text":"<pre><code>import os\nos.environ['PROFILIS_DEBUG'] = '1'\n\n# This will enable debug logging\nprofilis = ProfilisFlask(app, collector=collector)\n</code></pre>"},{"location":"adapters/flask/#health-checks","title":"Health Checks","text":"<pre><code>@app.route('/_profilis/health')\ndef profilis_health():\n    \"\"\"Check Profilis collector health\"\"\"\n    return {\n        \"collector\": {\n            \"queue_size\": collector.queue.qsize(),\n            \"queue_max\": collector.queue.maxsize,\n            \"dropped_events\": getattr(collector, 'dropped_events', 0)\n        }\n    }\n</code></pre>"},{"location":"adapters/flask/#migration-from-v00x","title":"Migration from v0.0.x","text":"<p>If you're upgrading from an earlier version:</p> <pre><code># Old import (v0.0.x)\n# from profilis.integrations.flask_ext import ProfilisFlask\n\n# New import (v0.1.0)\nfrom profilis.flask.adapter import ProfilisFlask\n\n# Old configuration\n# sg = ProfilisFlask(app, ui_enabled=True, ui_prefix=\"/_profilis\")\n\n# New configuration\nexporter = JSONLExporter(dir=\"./logs\")\ncollector = AsyncCollector(exporter)\nprofilis = ProfilisFlask(app, collector=collector)\n\n# Add UI separately if needed\nui_bp = make_ui_blueprint(stats, ui_prefix=\"/_profilis\")\napp.register_blueprint(ui_bp)\n</code></pre>"},{"location":"architecture/architecture/","title":"Architecture","text":"<p>Profilis is built with a modular, non-blocking architecture designed for high performance and minimal overhead.</p>"},{"location":"architecture/architecture/#system-overview","title":"System Overview","text":"<pre><code>flowchart LR\n  subgraph App\n    FW[Framework adapters]\n    DEC[Decorators]\n    DBI[DB adapters]\n  end\n  subgraph Core\n    CTX[ContextVars]\n    EMT[Emitter]\n    Q[Async Collector]\n    ST[StatsStore]\n  end\n  subgraph Exporters\n    JSONL[JSONL]\n    PROM[Prometheus]\n    OTLP[(OTLP)]\n  end\n  subgraph UI\n    API[/metrics.json/]\n    HTML[Dashboard]\n  end\n  FW --&gt; EMT\n  DEC --&gt; EMT\n  DBI --&gt; EMT\n  EMT --&gt; ST\n  EMT --&gt; Q\n  Q --&gt; JSONL\n  Q --&gt; PROM\n  Q --&gt; OTLP\n  ST --&gt; API --&gt; HTML</code></pre>"},{"location":"architecture/architecture/#core-components","title":"Core Components","text":""},{"location":"architecture/architecture/#asynccollector","title":"AsyncCollector","text":"<p>The heart of Profilis's non-blocking architecture.</p> <p>Responsibilities: - Asynchronous event collection and batching - Backpressure handling with configurable queue sizes - Efficient batch processing and export - Memory management and garbage collection</p> <p>Key Features: - Queue Management: Configurable bounded queues with drop-oldest policy - Batch Processing: Configurable batch sizes for optimal throughput - Flush Scheduling: Configurable flush intervals for latency vs. throughput trade-offs - Backpressure Handling: Automatic event dropping under load</p> <p>Configuration: <pre><code>collector = AsyncCollector(\n    exporter,\n    queue_size=2048,        # Maximum events in memory\n    batch_max=128,          # Maximum events per batch\n    flush_interval=0.1,     # Flush interval in seconds\n    drop_oldest=True        # Drop events under backpressure\n)\n</code></pre></p>"},{"location":"architecture/architecture/#emitter","title":"Emitter","text":"<p>High-performance event creation and emission.</p> <p>Responsibilities: - Event creation with minimal allocations - Runtime context integration - Event type specialization (REQ, FN, DB) - Performance optimization for hot paths</p> <p>Performance Characteristics: - Event Creation: \u226415\u00b5s per event - Memory Overhead: ~100 bytes per event - Allocation Efficiency: Minimal object creation - Hot Path Optimization: Inline critical operations</p> <p>Event Types: <pre><code># Request events\nemitter.emit_req(\"/api/users\", 200, dur_ns=15000000)\n\n# Function events\nemitter.emit_fn(\"expensive_calculation\", dur_ns=5000000, error=False)\n\n# Database events\nemitter.emit_db(\"SELECT * FROM users\", dur_ns=8000000, rows=100)\n</code></pre></p>"},{"location":"architecture/architecture/#runtime-context","title":"Runtime Context","text":"<p>Distributed tracing and context management.</p> <p>Components: - Context Variables: Thread-local and async context storage - Trace Management: Unique trace and span ID generation - Context Propagation: Automatic context inheritance - Async Support: Full async/await compatibility</p> <p>Usage: <pre><code>from profilis.runtime import use_span, span_id, get_trace_id, get_span_id\n\n# Create distributed trace context\nwith use_span(trace_id=span_id()):\n    current_trace = get_trace_id()\n\n    # Nested spans inherit trace context\n    with use_span(span_id=span_id()):\n        nested_span = get_span_id()\n        # All events inherit the trace context\n</code></pre></p>"},{"location":"architecture/architecture/#framework-integration","title":"Framework Integration","text":""},{"location":"architecture/architecture/#flask-adapter","title":"Flask Adapter","text":"<p>Automatic request/response profiling with hooks.</p> <p>Integration Points: - before_request: Start timing and create context - after_request: Record response metrics and timing - teardown_request: Handle exceptions and cleanup</p> <p>Features: - Automatic route detection - Configurable sampling rates - Route exclusion patterns - Exception tracking - Bytes in/out monitoring</p> <p>Configuration: <pre><code>profilis = ProfilisFlask(\n    app,\n    collector=collector,\n    exclude_routes=[\"/health\", \"/metrics\"],\n    sample=0.1  # 10% sampling\n)\n</code></pre></p>"},{"location":"architecture/architecture/#sqlalchemy-instrumentation","title":"SQLAlchemy Instrumentation","text":"<p>Database query profiling and monitoring.</p> <p>Integration Points: - Cursor Execution: Hook before/after query execution - Query Analysis: Parse and categorize SQL queries - Performance Metrics: Track execution time and row counts - Security: Query redaction for sensitive data</p> <p>Features: - Microsecond precision timing - Automatic query redaction - Row count tracking - Async engine support - Query pattern analysis</p>"},{"location":"architecture/architecture/#data-flow","title":"Data Flow","text":""},{"location":"architecture/architecture/#event-lifecycle","title":"Event Lifecycle","text":"<pre><code>sequenceDiagram\n    participant App as Application\n    participant Emitter as Emitter\n    participant Collector as AsyncCollector\n    participant Exporter as Exporter\n    participant Storage as Storage\n\n    App-&gt;&gt;Emitter: emit_req/fn/db()\n    Emitter-&gt;&gt;Collector: enqueue(event)\n    Collector-&gt;&gt;Collector: batch events\n    loop Every flush_interval\n        Collector-&gt;&gt;Exporter: export(batch)\n        Exporter-&gt;&gt;Storage: write events\n    end</code></pre>"},{"location":"architecture/architecture/#performance-characteristics","title":"Performance Characteristics","text":"<p>Event Processing Pipeline: 1. Event Creation: \u226415\u00b5s (Emitter) 2. Queue Enqueue: \u22641\u00b5s (AsyncCollector) 3. Batch Processing: \u22645\u00b5s per batch 4. Export: Varies by exporter (JSONL: \u2264100\u00b5s per batch)</p> <p>Memory Management: - Event Size: ~100 bytes per event - Queue Memory: queue_size \u00d7 100 bytes - Batch Memory: batch_max \u00d7 100 bytes - Total Overhead: (queue_size + batch_max) \u00d7 100 bytes</p>"},{"location":"architecture/architecture/#exporters","title":"Exporters","text":""},{"location":"architecture/architecture/#jsonl-exporter","title":"JSONL Exporter","text":"<p>Rotating log files with configurable retention.</p> <p>Features: - Automatic file rotation by size/time - Atomic file operations - Configurable naming patterns - Compression support</p> <p>Configuration: <pre><code>exporter = JSONLExporter(\n    dir=\"./logs\",\n    rotate_bytes=1024*1024,  # 1MB per file\n    rotate_secs=3600,        # Hourly rotation\n    filename_template=\"profilis-{timestamp}.jsonl\"\n)\n</code></pre></p>"},{"location":"architecture/architecture/#console-exporter","title":"Console Exporter","text":"<p>Development-friendly output formatting.</p> <p>Features: - Pretty-printed output - Color-coded event types - Compact mode for production - Configurable formatting</p>"},{"location":"architecture/architecture/#prometheus-exporter-planned","title":"Prometheus Exporter (Planned)","text":"<p>Native Prometheus metrics integration.</p> <p>Planned Features: - HTTP metrics endpoint - Custom metric definitions - Grafana dashboard templates - Alerting rules</p>"},{"location":"architecture/architecture/#ui-dashboard","title":"UI Dashboard","text":""},{"location":"architecture/architecture/#statsstore","title":"StatsStore","text":"<p>In-memory statistics with rolling windows.</p> <p>Features: - 15-minute rolling window (configurable) - Real-time metric calculation - Error tracking and display - Performance trend analysis</p> <p>Metrics: - Request latency percentiles - Error rates by route - Throughput statistics - Database query performance</p>"},{"location":"architecture/architecture/#dashboard-components","title":"Dashboard Components","text":"<p>Real-time Metrics: - Request latency charts - Error rate monitoring - Throughput graphs - Database performance</p> <p>Error Tracking: - Recent error display - Exception type analysis - Route-specific error rates - Stack trace information</p>"},{"location":"architecture/architecture/#performance-optimization","title":"Performance Optimization","text":""},{"location":"architecture/architecture/#memory-management","title":"Memory Management","text":"<p>Efficient Data Structures: - Minimal object allocation - Reusable event dictionaries - Efficient string handling - Optimized serialization</p> <p>Garbage Collection: - Minimal GC pressure - Efficient memory reuse - Predictable memory usage - Low fragmentation</p>"},{"location":"architecture/architecture/#async-processing","title":"Async Processing","text":"<p>Non-blocking Operations: - Async file I/O - Non-blocking queues - Efficient batching - Background processing</p> <p>Concurrency Handling: - Thread-safe operations - Async context support - Efficient locking - Minimal contention</p>"},{"location":"architecture/architecture/#scalability-considerations","title":"Scalability Considerations","text":""},{"location":"architecture/architecture/#horizontal-scaling","title":"Horizontal Scaling","text":"<p>Multiple Instances: - Stateless collectors - Shared storage backends - Load balancing support - Distributed tracing</p> <p>Performance Limits: - Single instance: 100K+ events/second - Memory usage: Linear with queue size - CPU usage: Minimal overhead - Network I/O: Exporter dependent</p>"},{"location":"architecture/architecture/#vertical-scaling","title":"Vertical Scaling","text":"<p>Resource Optimization: - Queue size tuning - Batch size optimization - Flush interval adjustment - Memory allocation tuning</p> <p>Monitoring: - Queue depth monitoring - Memory usage tracking - Performance metrics - Health checks</p>"},{"location":"architecture/architecture/#security-considerations","title":"Security Considerations","text":""},{"location":"architecture/architecture/#data-privacy","title":"Data Privacy","text":"<p>Query Redaction: - Automatic SQL parameter hiding - Custom redaction rules - Sensitive data protection - Audit trail maintenance</p> <p>Access Control: - Dashboard authentication - API endpoint protection - Role-based access - Audit logging</p>"},{"location":"architecture/architecture/#production-hardening","title":"Production Hardening","text":"<p>Error Handling: - Graceful degradation - Circuit breaker patterns - Fallback mechanisms - Health monitoring</p> <p>Resource Protection: - Memory limits - CPU throttling - File descriptor limits - Network rate limiting</p>"},{"location":"architecture/architecture/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"architecture/architecture/#health-checks","title":"Health Checks","text":"<p>System Health: - Collector status - Exporter health - Queue depth monitoring - Error rate tracking</p> <p>Performance Metrics: - Event processing rate - Memory usage - CPU utilization - I/O performance</p>"},{"location":"architecture/architecture/#alerting","title":"Alerting","text":"<p>Threshold Monitoring: - Queue depth alerts - Error rate thresholds - Performance degradation - Resource exhaustion</p> <p>Integration: - Prometheus alerts - Grafana dashboards - PagerDuty integration - Slack notifications</p>"},{"location":"architecture/architecture/#future-architecture","title":"Future Architecture","text":""},{"location":"architecture/architecture/#planned-enhancements","title":"Planned Enhancements","text":"<p>v0.2.0: - Additional database integrations - Enhanced performance monitoring - Better error handling</p> <p>v0.3.0: - ASGI framework support - WebSocket profiling - Advanced async features</p> <p>v0.4.0: - Prometheus integration - Advanced sampling - Resilience features</p> <p>v1.0.0: - Enterprise features - High availability - Comprehensive monitoring</p>"},{"location":"databases/sqlalchemy/","title":"SQLAlchemy Instrumentation","text":"<p>Profilis provides automatic SQLAlchemy query profiling with minimal configuration.</p>"},{"location":"databases/sqlalchemy/#quick-start","title":"Quick Start","text":"<pre><code>from sqlalchemy import create_engine\nfrom profilis.sqlalchemy.instrumentation import instrument_engine\nfrom profilis.core.emitter import Emitter\nfrom profilis.exporters.jsonl import JSONLExporter\nfrom profilis.core.async_collector import AsyncCollector\n\n# Setup Profilis\nexporter = JSONLExporter(dir=\"./logs\")\ncollector = AsyncCollector(exporter)\nemitter = Emitter(collector)\n\n# Create SQLAlchemy engine\nengine = create_engine(\"sqlite:///app.db\")\n\n# Instrument the engine\ninstrument_engine(engine, emitter)\n\n# All queries will now be automatically profiled\n</code></pre>"},{"location":"databases/sqlalchemy/#async-sqlalchemy-support","title":"Async SQLAlchemy Support","text":"<pre><code>from sqlalchemy.ext.asyncio import create_async_engine\nfrom profilis.sqlalchemy.instrumentation import instrument_async_engine\n\n# Create async engine\nasync_engine = create_async_engine(\"sqlite+aiosqlite:///app.db\")\n\n# Instrument the async engine\nemitter = Emitter(collector)\ninstrument_async_engine(async_engine, emitter)\n\n# All async queries will now be automatically profiled\n</code></pre>"},{"location":"databases/sqlalchemy/#features","title":"Features","text":""},{"location":"databases/sqlalchemy/#automatic-query-profiling","title":"Automatic Query Profiling","text":"<ul> <li>Query Timing: Measures execution time with microsecond precision</li> <li>Row Counts: Tracks number of rows returned/affected</li> <li>Query Text: Captures actual SQL queries (with redaction support)</li> <li>Async Support: Works with both sync and async engines</li> <li>Performance Metrics: Tracks slow queries and bottlenecks</li> </ul>"},{"location":"databases/sqlalchemy/#performance-optimized","title":"Performance Optimized","text":"<ul> <li>Non-blocking: All profiling happens asynchronously</li> <li>Minimal Overhead: \u226415\u00b5s per query profiling cost</li> <li>Batch Processing: Efficient event collection and export</li> <li>Memory Efficient: Lightweight event representation</li> </ul>"},{"location":"databases/sqlalchemy/#configuration","title":"Configuration","text":""},{"location":"databases/sqlalchemy/#basic-instrumentation","title":"Basic Instrumentation","text":"<pre><code>from profilis.sqlalchemy.instrumentation import instrument_engine\nfrom profilis.core.emitter import Emitter\n\n# Simple instrumentation\nemitter = Emitter(collector)\ninstrument_engine(engine, emitter)\n\n# With custom options\ninstrument_engine(\n    engine,\n    emitter,\n    redact=True,              # Hide sensitive data (default: True)\n    max_len=200               # Maximum query length (default: 200)\n)\n</code></pre>"},{"location":"databases/sqlalchemy/#advanced-configuration","title":"Advanced Configuration","text":"<pre><code># Production configuration\ninstrument_engine(\n    engine,\n    emitter,\n    redact=True,                   # Always redact in production (default)\n    max_len=500                    # Truncate very long queries\n)\n</code></pre>"},{"location":"databases/sqlalchemy/#what-gets-profiled","title":"What Gets Profiled","text":""},{"location":"databases/sqlalchemy/#database-events-db","title":"Database Events (DB)","text":"<p>Each SQL query generates a <code>DB</code> event:</p> <pre><code>{\n  \"ts_ns\": 1703123456789000000,\n  \"trace_id\": \"trace-abc123\",\n  \"span_id\": \"span-def456\",\n  \"kind\": \"DB\",\n  \"query\": \"SELECT * FROM users WHERE id = ?\",\n  \"dur_ns\": 5000000,\n  \"rows\": 1,\n  \"engine\": \"sqlite:///app.db\"\n}\n</code></pre> <p>Fields: - <code>ts_ns</code>: Timestamp in nanoseconds - <code>trace_id</code>: Current trace identifier (if in trace context) - <code>span_id</code>: Current span identifier (if in span context) - <code>query</code>: SQL query text (may be redacted) - <code>dur_ns</code>: Query execution time in nanoseconds - <code>rows</code>: Number of rows returned/affected - <code>engine</code>: Database engine identifier</p>"},{"location":"databases/sqlalchemy/#query-metadata-db_meta","title":"Query Metadata (DB_META)","text":"<p>Additional query information is recorded:</p> <pre><code>{\n  \"kind\": \"DB_META\",\n  \"ts_ns\": 1703123456789000000,\n  \"trace_id\": \"trace-abc123\",\n  \"span_id\": \"span-def456\",\n  \"query_hash\": \"abc123def456\",\n  \"query_type\": \"SELECT\",\n  \"table\": \"users\",\n  \"parameters\": {\"id\": 123}\n}\n</code></pre>"},{"location":"databases/sqlalchemy/#integration-patterns","title":"Integration Patterns","text":""},{"location":"databases/sqlalchemy/#with-flask-adapter","title":"With Flask Adapter","text":"<pre><code>from flask import Flask\nfrom profilis.flask.adapter import ProfilisFlask\nfrom profilis.sqlalchemy.instrumentation import instrument_engine\nfrom profilis.core.emitter import Emitter\n\n# Setup Flask with Profilis\napp = Flask(__name__)\nprofilis = ProfilisFlask(app, collector=collector)\n\n# Instrument SQLAlchemy\nengine = create_engine(\"sqlite:///app.db\")\nemitter = Emitter(collector)\ninstrument_engine(engine, emitter)\n\n# Now Flask requests and SQL queries are automatically correlated\n@app.route('/api/users/&lt;user_id&gt;')\ndef get_user(user_id):\n    # This query will be automatically profiled and linked to the request\n    user = engine.execute(\"SELECT * FROM users WHERE id = ?\", (user_id,)).fetchone()\n    return {\"user\": user}\n</code></pre>"},{"location":"databases/sqlalchemy/#with-function-profiling","title":"With Function Profiling","text":"<pre><code>from profilis.decorators.profile import profile_function\n\n@profile_function(emitter)\ndef get_user_data(user_id: int):\n    \"\"\"Profile both function execution and database queries\"\"\"\n    # SQLAlchemy queries are automatically profiled\n    user = engine.execute(\"SELECT * FROM users WHERE id = ?\", (user_id,)).fetchone()\n    posts = engine.execute(\"SELECT * FROM posts WHERE user_id = ?\", (user_id,)).fetchall()\n    return {\"user\": user, \"posts\": posts}\n</code></pre>"},{"location":"databases/sqlalchemy/#with-runtime-context","title":"With Runtime Context","text":"<pre><code>from profilis.runtime import use_span, span_id\n\ndef process_user_batch(user_ids: list[int]):\n    \"\"\"Process multiple users with distributed tracing\"\"\"\n    with use_span(trace_id=span_id()):\n        for user_id in user_ids:\n            with use_span(span_id=span_id()):\n                # Each query inherits the trace context\n                user = engine.execute(\"SELECT * FROM users WHERE id = ?\", (user_id,)).fetchone()\n                # Process user data...\n</code></pre>"},{"location":"databases/sqlalchemy/#query-redaction","title":"Query Redaction","text":""},{"location":"databases/sqlalchemy/#automatic-redaction","title":"Automatic Redaction","text":"<pre><code># Enable query redaction (recommended for production)\ninstrument_sqlalchemy(\n    engine,\n    collector,\n    redact_queries=True\n)\n\n# Queries with sensitive data are automatically redacted\n# Original: SELECT * FROM users WHERE email = 'user@example.com' AND password = 'secret'\n# Redacted: SELECT * FROM users WHERE email = ? AND password = ?\n</code></pre>"},{"location":"databases/sqlalchemy/#custom-redaction-rules","title":"Custom Redaction Rules","text":"<pre><code>import re\nfrom profilis.sqlalchemy.instrumentation import instrument_sqlalchemy\n\ndef custom_redactor(query: str) -&gt; str:\n    \"\"\"Custom query redaction logic\"\"\"\n    # Redact email addresses\n    query = re.sub(r\"'[^']*@[^']*'\", \"?\", query)\n    # Redact credit card numbers\n    query = re.sub(r\"'[0-9]{4}-[0-9]{4}-[0-9]{4}-[0-9]{4}'\", \"?\", query)\n    return query\n\ninstrument_sqlalchemy(\n    engine,\n    collector,\n    redact_queries=True,\n    query_redactor=custom_redactor\n)\n</code></pre>"},{"location":"databases/sqlalchemy/#performance-tuning","title":"Performance Tuning","text":""},{"location":"databases/sqlalchemy/#query-length-limiting","title":"Query Length Limiting","text":"<pre><code># Limit query text length to reduce memory usage\ninstrument_engine(\n    engine,\n    emitter,\n    max_len=100  # Truncate queries longer than 100 characters\n)\n</code></pre>"},{"location":"databases/sqlalchemy/#redaction-control","title":"Redaction Control","text":"<pre><code># Disable redaction for debugging (not recommended for production)\ninstrument_engine(\n    engine,\n    emitter,\n    redact=False  # Show full query text\n)\n</code></pre> <p>Note: The current implementation profiles all queries. For high-volume applications, consider implementing sampling at the collector level or using route-based sampling in Flask.</p>"},{"location":"databases/sqlalchemy/#monitoring-and-alerting","title":"Monitoring and Alerting","text":""},{"location":"databases/sqlalchemy/#slow-query-detection","title":"Slow Query Detection","text":"<pre><code>import logging\n\nlogger = logging.getLogger(__name__)\n\ndef monitor_slow_queries(collector):\n    \"\"\"Monitor for slow database queries\"\"\"\n    # This would be implemented based on your monitoring strategy\n    pass\n\n# Example: Alert on queries &gt; 1 second\nSLOW_QUERY_THRESHOLD = 1_000_000_000  # 1 second in nanoseconds\n</code></pre>"},{"location":"databases/sqlalchemy/#query-performance-metrics","title":"Query Performance Metrics","text":"<pre><code>from collections import defaultdict\nimport statistics\n\nclass QueryAnalyzer:\n    def __init__(self):\n        self.query_stats = defaultdict(list)\n\n    def analyze_query(self, query: str, duration_ns: int):\n        \"\"\"Analyze query performance\"\"\"\n        self.query_stats[query].append(duration_ns)\n\n        # Alert on slow queries\n        if duration_ns &gt; 1_000_000_000:  # 1 second\n            logger.warning(f\"Slow query detected: {query} ({duration_ns/1_000_000:.2f}ms)\")\n\n    def get_stats(self):\n        \"\"\"Get query performance statistics\"\"\"\n        stats = {}\n        for query, durations in self.query_stats.items():\n            stats[query] = {\n                \"count\": len(durations),\n                \"avg_ms\": statistics.mean(durations) / 1_000_000,\n                \"max_ms\": max(durations) / 1_000_000,\n                \"min_ms\": min(durations) / 1_000_000\n            }\n        return stats\n</code></pre>"},{"location":"databases/sqlalchemy/#testing","title":"Testing","text":""},{"location":"databases/sqlalchemy/#unit-testing","title":"Unit Testing","text":"<pre><code>import pytest\nfrom profilis.exporters.console import ConsoleExporter\n\n@pytest.fixture\ndef test_collector():\n    \"\"\"Test collector for unit tests\"\"\"\n    exporter = ConsoleExporter(pretty=False)\n    return AsyncCollector(exporter, queue_size=128, flush_interval=0.01)\n\n@pytest.fixture\ndef test_engine(test_collector):\n    \"\"\"Test engine with Profilis instrumentation\"\"\"\n    engine = create_engine(\"sqlite:///:memory:\")\n    emitter = Emitter(test_collector)\n    instrument_engine(engine, emitter)\n    return engine\n\ndef test_query_profiling(test_engine, test_collector):\n    \"\"\"Test that queries are profiled\"\"\"\n    # Execute a query\n    result = test_engine.execute(\"SELECT 1\").fetchone()\n\n    # Verify profiling data was collected\n    # (Implementation depends on your testing strategy)\n    assert result[0] == 1\n</code></pre>"},{"location":"databases/sqlalchemy/#integration-testing","title":"Integration Testing","text":"<pre><code>def test_sqlalchemy_integration(test_engine, test_collector):\n    \"\"\"Test SQLAlchemy integration with Profilis\"\"\"\n    # Create test data\n    test_engine.execute(\"CREATE TABLE test (id INTEGER, name TEXT)\")\n    test_engine.execute(\"INSERT INTO test VALUES (1, 'test')\")\n\n    # Query the data\n    result = test_engine.execute(\"SELECT * FROM test WHERE id = 1\").fetchone()\n\n    # Verify the result\n    assert result[0] == 1\n    assert result[1] == 'test'\n</code></pre>"},{"location":"databases/sqlalchemy/#troubleshooting","title":"Troubleshooting","text":""},{"location":"databases/sqlalchemy/#common-issues","title":"Common Issues","text":"<ol> <li>No Events Generated: Ensure the collector is properly configured</li> <li>Missing Query Text: Check if redaction is enabled</li> <li>Performance Impact: Use sampling and filtering for high-volume applications</li> <li>Async Engine Issues: Ensure proper async context setup</li> </ol>"},{"location":"databases/sqlalchemy/#debug-mode","title":"Debug Mode","text":"<pre><code>import os\nos.environ['PROFILIS_DEBUG'] = '1'\n\n# This will enable debug logging for SQLAlchemy instrumentation\nemitter = Emitter(collector)\ninstrument_engine(engine, emitter)\n</code></pre>"},{"location":"databases/sqlalchemy/#health-checks","title":"Health Checks","text":"<pre><code>def check_sqlalchemy_instrumentation(engine, collector):\n    \"\"\"Check if SQLAlchemy instrumentation is working\"\"\"\n    try:\n        # Execute a simple query\n        result = engine.execute(\"SELECT 1\").fetchone()\n\n        # Check if events were generated\n        # (Implementation depends on your monitoring strategy)\n\n        return True\n    except Exception as e:\n        logger.error(f\"SQLAlchemy instrumentation check failed: {e}\")\n        return False\n</code></pre>"},{"location":"databases/sqlalchemy/#best-practices","title":"Best Practices","text":"<ol> <li>Enable Redaction: Always enable query redaction in production (default behavior)</li> <li>Limit Query Length: Use <code>max_len</code> to prevent very long queries from consuming memory</li> <li>Monitor Performance: Track query performance metrics over time</li> <li>Use Async Engines: For async applications, use <code>instrument_async_engine()</code> with async SQLAlchemy engines</li> <li>Test Thoroughly: Test instrumentation in your specific environment</li> <li>Review Queries: Regularly review profiled queries for optimization opportunities</li> <li>Correlate with Requests: Use the same collector for both Flask and SQLAlchemy to correlate requests with queries</li> </ol>"},{"location":"exporters/jsonl/","title":"JSONL Exporter","text":"<p>The JSONL (JSON Lines) exporter writes profiling events to rotating log files in JSONL format.</p>"},{"location":"exporters/jsonl/#quick-start","title":"Quick Start","text":"<pre><code>from profilis.exporters.jsonl import JSONLExporter\nfrom profilis.core.async_collector import AsyncCollector\n\n# Basic setup\nexporter = JSONLExporter(dir=\"./logs\")\ncollector = AsyncCollector(exporter)\n\n# With rotation\nexporter = JSONLExporter(\n    dir=\"./logs\",\n    rotate_bytes=1024*1024,  # 1MB per file\n    rotate_secs=3600         # Rotate every hour\n)\n</code></pre>"},{"location":"exporters/jsonl/#features","title":"Features","text":""},{"location":"exporters/jsonl/#file-management","title":"File Management","text":"<ul> <li>Automatic Rotation: Rotate files by size or time</li> <li>Atomic Writes: Safe file rotation with atomic renames</li> <li>Configurable Retention: Control file sizes and rotation intervals</li> <li>Timestamped Names: Automatic timestamp-based file naming</li> </ul>"},{"location":"exporters/jsonl/#performance","title":"Performance","text":"<ul> <li>Non-blocking: Asynchronous file I/O</li> <li>Buffered Writes: Efficient batch writing</li> <li>Compression Ready: Easy integration with compression tools</li> <li>Low Memory: Minimal memory footprint</li> </ul>"},{"location":"exporters/jsonl/#configuration","title":"Configuration","text":""},{"location":"exporters/jsonl/#basic-configuration","title":"Basic Configuration","text":"<pre><code>from profilis.exporters.jsonl import JSONLExporter\n\n# Simple setup\nexporter = JSONLExporter(dir=\"./logs\")\n\n# With custom directory\nexporter = JSONLExporter(dir=\"/var/log/profilis\")\n</code></pre>"},{"location":"exporters/jsonl/#rotation-configuration","title":"Rotation Configuration","text":"<pre><code># Rotate by size only\nexporter = JSONLExporter(\n    dir=\"./logs\",\n    rotate_bytes=10*1024*1024  # 10MB per file\n)\n\n# Rotate by time only\nexporter = JSONLExporter(\n    dir=\"./logs\",\n    rotate_secs=86400  # Daily rotation\n)\n\n# Rotate by both size and time\nexporter = JSONLExporter(\n    dir=\"./logs\",\n    rotate_bytes=100*1024*1024,  # 100MB per file\n    rotate_secs=86400             # Daily rotation\n)\n</code></pre>"},{"location":"exporters/jsonl/#advanced-configuration","title":"Advanced Configuration","text":"<pre><code># Production configuration\nexporter = JSONLExporter(\n    dir=\"/var/log/profilis\",\n    rotate_bytes=100*1024*1024,  # 100MB files\n    rotate_secs=86400,            # Daily rotation\n    filename_template=\"profilis-{timestamp}.jsonl\",\n    compress_old_files=True,      # Compress rotated files\n    max_files=30                  # Keep last 30 files\n)\n</code></pre>"},{"location":"exporters/jsonl/#file-naming","title":"File Naming","text":""},{"location":"exporters/jsonl/#default-naming","title":"Default Naming","text":"<p>By default, files are named with timestamps:</p> <pre><code>logs/\n\u251c\u2500\u2500 profilis-20241227-120000.jsonl    # 12:00 rotation\n\u251c\u2500\u2500 profilis-20241227-130000.jsonl    # 13:00 rotation\n\u251c\u2500\u2500 profilis-20241227-140000.jsonl    # 14:00 rotation\n\u2514\u2500\u2500 profilis-20241227-150000.jsonl    # Current file\n</code></pre>"},{"location":"exporters/jsonl/#custom-naming","title":"Custom Naming","text":"<p>Use custom filename templates:</p> <pre><code># Custom template\nexporter = JSONLExporter(\n    dir=\"./logs\",\n    filename_template=\"app-{timestamp}-{index}.jsonl\"\n)\n\n# Result: app-20241227-120000-001.jsonl\n\n# With application name\nexporter = JSONLExporter(\n    dir=\"./logs\",\n    filename_template=\"{app_name}-{timestamp}.jsonl\",\n    app_name=\"myapp\"\n)\n\n# Result: myapp-20241227-120000.jsonl\n</code></pre>"},{"location":"exporters/jsonl/#event-format","title":"Event Format","text":""},{"location":"exporters/jsonl/#request-events","title":"Request Events","text":"<pre><code>{\"ts_ns\": 1703123456789000000, \"trace_id\": \"trace-abc123\", \"span_id\": \"span-def456\", \"kind\": \"REQ\", \"route\": \"/api/users\", \"status\": 200, \"dur_ns\": 15000000}\n{\"ts_ns\": 1703123456790000000, \"trace_id\": \"trace-abc124\", \"span_id\": \"span-def457\", \"kind\": \"REQ\", \"route\": \"/api/users/1\", \"status\": 200, \"dur_ns\": 8000000}\n</code></pre>"},{"location":"exporters/jsonl/#function-events","title":"Function Events","text":"<pre><code>{\"ts_ns\": 1703123456791000000, \"trace_id\": \"trace-abc123\", \"span_id\": \"span-def458\", \"kind\": \"FN\", \"fn\": \"get_user_data\", \"dur_ns\": 12000000, \"error\": false}\n</code></pre>"},{"location":"exporters/jsonl/#database-events","title":"Database Events","text":"<pre><code>{\"ts_ns\": 1703123456792000000, \"trace_id\": \"trace-abc123\", \"span_id\": \"span-def459\", \"kind\": \"DB\", \"query\": \"SELECT * FROM users WHERE id = ?\", \"dur_ns\": 5000000, \"rows\": 1}\n</code></pre>"},{"location":"exporters/jsonl/#integration-examples","title":"Integration Examples","text":""},{"location":"exporters/jsonl/#with-flask","title":"With Flask","text":"<pre><code>from flask import Flask\nfrom profilis.flask.adapter import ProfilisFlask\nfrom profilis.exporters.jsonl import JSONLExporter\nfrom profilis.core.async_collector import AsyncCollector\n\n# Setup JSONL exporter\nexporter = JSONLExporter(\n    dir=\"./logs\",\n    rotate_bytes=1024*1024,  # 1MB per file\n    rotate_secs=3600         # Hourly rotation\n)\n\ncollector = AsyncCollector(exporter)\n\n# Integrate with Flask\napp = Flask(__name__)\nprofilis = ProfilisFlask(app, collector=collector)\n</code></pre>"},{"location":"exporters/jsonl/#with-multiple-exporters","title":"With Multiple Exporters","text":"<pre><code>from profilis.exporters.console import ConsoleExporter\nfrom profilis.exporters.jsonl import JSONLExporter\nfrom profilis.core.async_collector import AsyncCollector\n\n# Development: Console + JSONL\nif app.debug:\n    console_exporter = ConsoleExporter(pretty=True)\n    jsonl_exporter = JSONLExporter(dir=\"./logs\")\n\n    # Use both exporters\n    collector = AsyncCollector([console_exporter, jsonl_exporter])\nelse:\n    # Production: JSONL only\n    jsonl_exporter = JSONLExporter(\n        dir=\"/var/log/profilis\",\n        rotate_bytes=100*1024*1024,\n        rotate_secs=86400\n    )\n    collector = AsyncCollector(jsonl_exporter)\n</code></pre>"},{"location":"exporters/jsonl/#with-custom-event-processing","title":"With Custom Event Processing","text":"<pre><code>from profilis.exporters.jsonl import JSONLExporter\nfrom profilis.core.async_collector import AsyncCollector\nimport json\n\nclass CustomJSONLExporter(JSONLExporter):\n    def export(self, events: list[dict]) -&gt; None:\n        \"\"\"Custom export logic\"\"\"\n        for event in events:\n            # Add custom fields\n            event['exported_at'] = time.time()\n            event['environment'] = 'production'\n\n            # Write to file\n            line = json.dumps(event, separators=(',', ':')) + '\\n'\n            self._write_line(line)\n\n# Use custom exporter\nexporter = CustomJSONLExporter(dir=\"./logs\")\ncollector = AsyncCollector(exporter)\n</code></pre>"},{"location":"exporters/jsonl/#file-management_1","title":"File Management","text":""},{"location":"exporters/jsonl/#automatic-cleanup","title":"Automatic Cleanup","text":"<pre><code># Keep only last 10 files\nexporter = JSONLExporter(\n    dir=\"./logs\",\n    rotate_bytes=1024*1024,\n    max_files=10\n)\n\n# Keep files for 7 days\nexporter = JSONLExporter(\n    dir=\"./logs\",\n    rotate_secs=86400,\n    max_age_secs=7*86400\n)\n</code></pre>"},{"location":"exporters/jsonl/#manual-cleanup","title":"Manual Cleanup","text":"<pre><code>import os\nimport glob\nfrom datetime import datetime, timedelta\n\ndef cleanup_old_files(log_dir: str, max_age_days: int = 7):\n    \"\"\"Manually cleanup old log files\"\"\"\n    cutoff = datetime.now() - timedelta(days=max_age_days)\n\n    for file_path in glob.glob(os.path.join(log_dir, \"*.jsonl\")):\n        file_time = datetime.fromtimestamp(os.path.getctime(file_path))\n        if file_time &lt; cutoff:\n            os.remove(file_path)\n            print(f\"Removed old file: {file_path}\")\n\n# Cleanup old files\ncleanup_old_files(\"./logs\", max_age_days=30)\n</code></pre>"},{"location":"exporters/jsonl/#monitoring-and-health-checks","title":"Monitoring and Health Checks","text":""},{"location":"exporters/jsonl/#exporter-health","title":"Exporter Health","text":"<pre><code>def check_exporter_health(exporter: JSONLExporter) -&gt; dict:\n    \"\"\"Check exporter health status\"\"\"\n    try:\n        # Check if directory is writable\n        test_file = os.path.join(exporter.dir, \"health-check.tmp\")\n        with open(test_file, 'w') as f:\n            f.write(\"health check\")\n        os.remove(test_file)\n\n        # Check current file status\n        current_file = exporter._get_current_file_path()\n        file_size = os.path.getsize(current_file) if os.path.exists(current_file) else 0\n\n        return {\n            \"status\": \"healthy\",\n            \"directory\": exporter.dir,\n            \"current_file\": current_file,\n            \"current_file_size\": file_size,\n            \"rotation_config\": {\n                \"rotate_bytes\": exporter.rotate_bytes,\n                \"rotate_secs\": exporter.rotate_secs\n            }\n        }\n    except Exception as e:\n        return {\n            \"status\": \"unhealthy\",\n            \"error\": str(e)\n        }\n</code></pre>"},{"location":"exporters/jsonl/#file-size-monitoring","title":"File Size Monitoring","text":"<pre><code>import os\nfrom pathlib import Path\n\ndef monitor_log_directory(log_dir: str) -&gt; dict:\n    \"\"\"Monitor log directory usage\"\"\"\n    path = Path(log_dir)\n\n    if not path.exists():\n        return {\"error\": \"Directory does not exist\"}\n\n    total_size = sum(f.stat().st_size for f in path.rglob('*.jsonl'))\n    file_count = len(list(path.rglob('*.jsonl')))\n\n    return {\n        \"directory\": log_dir,\n        \"total_size_bytes\": total_size,\n        \"total_size_mb\": total_size / (1024 * 1024),\n        \"file_count\": file_count,\n        \"files\": [\n            {\n                \"name\": f.name,\n                \"size_bytes\": f.stat().st_size,\n                \"modified\": f.stat().st_mtime\n            }\n            for f in path.glob('*.jsonl')\n        ]\n    }\n</code></pre>"},{"location":"exporters/jsonl/#performance-tuning","title":"Performance Tuning","text":""},{"location":"exporters/jsonl/#buffer-configuration","title":"Buffer Configuration","text":"<pre><code># Large buffers for high throughput\nexporter = JSONLExporter(\n    dir=\"./logs\",\n    buffer_size=64*1024  # 64KB buffer\n)\n\n# Small buffers for low latency\nexporter = JSONLExporter(\n    dir=\"./logs\",\n    buffer_size=4*1024   # 4KB buffer\n)\n</code></pre>"},{"location":"exporters/jsonl/#compression","title":"Compression","text":"<pre><code>import gzip\n\nclass CompressedJSONLExporter(JSONLExporter):\n    def _write_line(self, line: str) -&gt; None:\n        \"\"\"Write compressed lines\"\"\"\n        compressed = gzip.compress(line.encode('utf-8'))\n        self._current_file.write(compressed)\n\n# Use compressed exporter\nexporter = CompressedJSONLExporter(\n    dir=\"./logs\",\n    filename_template=\"profilis-{timestamp}.jsonl.gz\"\n)\n</code></pre>"},{"location":"exporters/jsonl/#troubleshooting","title":"Troubleshooting","text":""},{"location":"exporters/jsonl/#common-issues","title":"Common Issues","text":"<ol> <li>Permission Errors: Ensure write permissions to the log directory</li> <li>Disk Space: Monitor available disk space for log rotation</li> <li>File Locks: Check for file locking issues during rotation</li> <li>Performance: Adjust buffer sizes for your workload</li> </ol>"},{"location":"exporters/jsonl/#debug-mode","title":"Debug Mode","text":"<pre><code>import os\nos.environ['PROFILIS_DEBUG'] = '1'\n\n# This will enable debug logging for the JSONL exporter\nexporter = JSONLExporter(dir=\"./logs\")\n</code></pre>"},{"location":"exporters/jsonl/#log-rotation-issues","title":"Log Rotation Issues","text":"<pre><code>def diagnose_rotation_issues(exporter: JSONLExporter):\n    \"\"\"Diagnose log rotation problems\"\"\"\n    issues = []\n\n    # Check directory permissions\n    if not os.access(exporter.dir, os.W_OK):\n        issues.append(f\"Directory {exporter.dir} is not writable\")\n\n    # Check disk space\n    statvfs = os.statvfs(exporter.dir)\n    free_space = statvfs.f_frsize * statvfs.f_bavail\n    if free_space &lt; exporter.rotate_bytes:\n        issues.append(f\"Insufficient disk space: {free_space} bytes available\")\n\n    # Check current file\n    current_file = exporter._get_current_file_path()\n    if os.path.exists(current_file):\n        file_size = os.path.getsize(current_file)\n        if file_size &gt; exporter.rotate_bytes:\n            issues.append(f\"Current file exceeds rotation size: {file_size} &gt; {exporter.rotate_bytes}\")\n\n    return issues\n</code></pre>"},{"location":"exporters/jsonl/#best-practices","title":"Best Practices","text":"<ol> <li>Use Appropriate Rotation: Balance file size vs. rotation frequency</li> <li>Monitor Disk Usage: Set up alerts for disk space</li> <li>Implement Cleanup: Use automatic or manual cleanup strategies</li> <li>Test Rotation: Verify rotation works in your environment</li> <li>Backup Strategy: Consider backup and archival policies</li> <li>Performance Monitoring: Monitor exporter performance impact</li> </ol>"},{"location":"guides/configuration/","title":"Configuration","text":"<p>Profilis provides extensive configuration options for tuning performance, controlling data collection, and customizing behavior.</p>"},{"location":"guides/configuration/#core-configuration","title":"Core Configuration","text":""},{"location":"guides/configuration/#asynccollector-settings","title":"AsyncCollector Settings","text":"<p>The <code>AsyncCollector</code> is the heart of Profilis's non-blocking architecture:</p> <pre><code>from profilis.core.async_collector import AsyncCollector\n\ncollector = AsyncCollector(\n    exporter,\n    queue_size=2048,        # Maximum events in memory\n    batch_max=128,          # Maximum events per batch\n    flush_interval=0.1,     # Flush interval in seconds\n    drop_oldest=True        # Drop events under backpressure\n)\n</code></pre> <p>Key Parameters: - <code>queue_size</code>: Maximum number of events that can be queued (default: 2048) - <code>batch_max</code>: Maximum events per batch for efficient processing (default: 128) - <code>flush_interval</code>: How often to flush events to exporters (default: 0.1s) - <code>drop_oldest</code>: Whether to drop old events under backpressure (default: True)</p>"},{"location":"guides/configuration/#performance-tuning","title":"Performance Tuning","text":""},{"location":"guides/configuration/#high-throughput-configuration","title":"High-Throughput Configuration","text":"<pre><code># For high-volume applications\ncollector = AsyncCollector(\n    exporter,\n    queue_size=8192,        # Large queue for high concurrency\n    batch_max=256,          # Larger batches for efficiency\n    flush_interval=0.05,    # More frequent flushing\n    drop_oldest=True        # Drop events under backpressure\n)\n</code></pre>"},{"location":"guides/configuration/#low-latency-configuration","title":"Low-Latency Configuration","text":"<pre><code># For low-latency requirements\ncollector = AsyncCollector(\n    exporter,\n    queue_size=512,         # Smaller queue for lower latency\n    batch_max=32,           # Smaller batches for faster processing\n    flush_interval=0.01,    # Very frequent flushing\n    drop_oldest=False       # Don't drop events\n)\n</code></pre>"},{"location":"guides/configuration/#framework-specific-configuration","title":"Framework-Specific Configuration","text":""},{"location":"guides/configuration/#flask-adapter","title":"Flask Adapter","text":"<pre><code>from profilis.flask.adapter import ProfilisFlask\n\nprofilis = ProfilisFlask(\n    app,\n    collector=collector,\n    exclude_routes=[\"/health\", \"/metrics\", \"/static\"],  # Routes to ignore\n    sample=0.1  # Sample 10% of requests\n)\n</code></pre> <p>Configuration Options: - <code>collector</code>: Required AsyncCollector instance - <code>exclude_routes</code>: List of route prefixes to exclude from profiling - <code>sample</code>: Sampling rate from 0.0 (0%) to 1.0 (100%)</p>"},{"location":"guides/configuration/#route-exclusion-patterns","title":"Route Exclusion Patterns","text":"<pre><code># Exclude health and monitoring endpoints\nexclude_routes = [\n    \"/health\",\n    \"/metrics\",\n    \"/_profilis\",  # Built-in dashboard\n    \"/static\",     # Static assets\n    \"/admin\"       # Admin routes\n]\n\nprofilis = ProfilisFlask(app, collector=collector, exclude_routes=exclude_routes)\n</code></pre>"},{"location":"guides/configuration/#sampling-configuration","title":"Sampling Configuration","text":""},{"location":"guides/configuration/#random-sampling","title":"Random Sampling","text":"<pre><code># Sample 5% of requests in production\nprofilis = ProfilisFlask(app, collector=collector, sample=0.05)\n\n# Sample 100% in development\nprofilis = ProfilisFlask(app, collector=collector, sample=1.0)\n</code></pre>"},{"location":"guides/configuration/#route-based-sampling","title":"Route-Based Sampling","text":"<pre><code># Different sampling rates for different route patterns\nprofilis = ProfilisFlask(\n    app,\n    collector=collector,\n    exclude_routes=[\"/health\", \"/metrics\"],  # Always exclude\n    sample=0.1  # 10% sampling for all other routes\n)\n</code></pre>"},{"location":"guides/configuration/#exporter-configuration","title":"Exporter Configuration","text":""},{"location":"guides/configuration/#jsonl-exporter","title":"JSONL Exporter","text":"<pre><code>from profilis.exporters.jsonl import JSONLExporter\n\nexporter = JSONLExporter(\n    dir=\"./logs\",                    # Output directory\n    rotate_bytes=1024*1024,         # Rotate at 1MB\n    rotate_secs=3600,               # Rotate every hour\n    filename_template=\"profilis-{timestamp}.jsonl\"\n)\n</code></pre> <p>Rotation Options: - <code>rotate_bytes</code>: Rotate when file reaches this size - <code>rotate_secs</code>: Rotate after this many seconds - <code>dir</code>: Output directory for log files - <code>filename_template</code>: Custom filename pattern</p>"},{"location":"guides/configuration/#console-exporter","title":"Console Exporter","text":"<pre><code>from profilis.exporters.console import ConsoleExporter\n\n# Pretty-printed output for development\nexporter = ConsoleExporter(pretty=True)\n\n# Compact output for production\nexporter = ConsoleExporter(pretty=False)\n</code></pre>"},{"location":"guides/configuration/#environment-variables","title":"Environment Variables","text":"<p>Configure Profilis behavior through environment variables:</p> <pre><code># Enable debug mode\nexport PROFILIS_DEBUG=1\n\n# Set default log directory\nexport PROFILIS_LOG_DIR=/var/log/profilis\n\n# Configure sampling rate (0.0 to 1.0)\nexport PROFILIS_SAMPLE_RATE=0.1\n\n# Set queue size\nexport PROFILIS_QUEUE_SIZE=4096\n\n# Set batch size\nexport PROFILIS_BATCH_MAX=256\n\n# Set flush interval\nexport PROFILIS_FLUSH_INTERVAL=0.05\n</code></pre>"},{"location":"guides/configuration/#runtime-context-configuration","title":"Runtime Context Configuration","text":""},{"location":"guides/configuration/#trace-and-span-management","title":"Trace and Span Management","text":"<pre><code>from profilis.runtime import use_span, span_id, get_trace_id, get_span_id\n\n# Create distributed trace context\nwith use_span(trace_id=\"trace-123\", span_id=\"span-456\"):\n    current_trace = get_trace_id()  # \"trace-123\"\n    current_span = get_span_id()    # \"span-456\"\n\n    # Nested spans inherit trace context\n    with use_span(span_id=\"span-789\"):\n        nested_span = get_span_id()  # \"span-789\"\n        parent_trace = get_trace_id() # \"trace-123\"\n</code></pre>"},{"location":"guides/configuration/#dashboard-configuration","title":"Dashboard Configuration","text":""},{"location":"guides/configuration/#ui-blueprint-settings","title":"UI Blueprint Settings","text":"<pre><code>from profilis.flask.ui import make_ui_blueprint\nfrom profilis.core.stats import StatsStore\n\n# Configure stats store\nstats = StatsStore(\n    window_minutes=15,      # Rolling window size\n    max_errors=100          # Maximum errors to track\n)\n\n# Mount dashboard with custom settings\nui_bp = make_ui_blueprint(\n    stats,\n    ui_prefix=\"/_profilis\",     # URL prefix\n    ui_auth_token=\"secret123\"   # Optional authentication\n)\napp.register_blueprint(ui_bp)\n</code></pre>"},{"location":"guides/configuration/#production-configuration","title":"Production Configuration","text":""},{"location":"guides/configuration/#recommended-production-settings","title":"Recommended Production Settings","text":"<pre><code># Production-ready configuration\nexporter = JSONLExporter(\n    dir=\"/var/log/profilis\",\n    rotate_bytes=100*1024*1024,  # 100MB files\n    rotate_secs=86400            # Daily rotation\n)\n\ncollector = AsyncCollector(\n    exporter,\n    queue_size=4096,        # Larger queue for production\n    batch_max=256,          # Larger batches\n    flush_interval=0.1,     # 100ms flush interval\n    drop_oldest=True        # Drop under pressure\n)\n\nprofilis = ProfilisFlask(\n    app,\n    collector=collector,\n    exclude_routes=[\"/health\", \"/metrics\", \"/_profilis\"],\n    sample=0.1              # 10% sampling in production\n)\n</code></pre>"},{"location":"guides/configuration/#monitoring-and-alerting","title":"Monitoring and Alerting","text":"<pre><code># Add custom monitoring\nimport logging\n\nlogger = logging.getLogger(__name__)\n\ndef monitor_collector(collector):\n    \"\"\"Monitor collector health\"\"\"\n    if collector.queue_size &gt; collector.queue.maxsize * 0.8:\n        logger.warning(\"Collector queue is 80% full\")\n\n    if collector.dropped_events &gt; 0:\n        logger.error(f\"Collector dropped {collector.dropped_events} events\")\n</code></pre>"},{"location":"guides/configuration/#configuration-validation","title":"Configuration Validation","text":"<p>Profilis validates configuration at runtime:</p> <pre><code># Invalid sampling rate will raise ValueError\ntry:\n    profilis = ProfilisFlask(app, collector=collector, sample=1.5)\nexcept ValueError as e:\n    print(f\"Invalid configuration: {e}\")\n\n# Invalid queue size will raise ValueError\ntry:\n    collector = AsyncCollector(exporter, queue_size=0)\nexcept ValueError as e:\n    print(f\"Invalid configuration: {e}\")\n</code></pre>"},{"location":"guides/configuration/#best-practices","title":"Best Practices","text":"<ol> <li>Start Conservative: Begin with default settings and tune based on your needs</li> <li>Monitor Queue Size: Watch for queue backpressure in production</li> <li>Use Sampling in Production: Start with 10% sampling and adjust based on volume</li> <li>Exclude Health Endpoints: Always exclude monitoring endpoints from profiling</li> <li>Configure Log Rotation: Set appropriate rotation policies for your log storage</li> <li>Test Performance Impact: Measure overhead in your specific environment</li> </ol>"},{"location":"guides/getting-started/","title":"Getting Started","text":""},{"location":"guides/getting-started/#installation","title":"Installation","text":"<p>Install Profilis with the dependencies you need:</p>"},{"location":"guides/getting-started/#option-1-using-pip-with-extras-recommended","title":"Option 1: Using pip with extras (Recommended)","text":"<pre><code># Core package only\npip install profilis\n\n# With Flask support\npip install profilis[flask]\n\n# With database support\npip install profilis[flask,sqlalchemy]\n\n# With all integrations\npip install profilis[all]\n</code></pre>"},{"location":"guides/getting-started/#option-2-using-requirements-files","title":"Option 2: Using requirements files","text":"<pre><code># Minimal setup (core only)\npip install -r requirements-minimal.txt\n\n# Flask integration\npip install -r requirements-flask.txt\n\n# SQLAlchemy integration\npip install -r requirements-sqlalchemy.txt\n\n# All integrations\npip install -r requirements-all.txt\n</code></pre>"},{"location":"guides/getting-started/#option-3-manual-installation","title":"Option 3: Manual installation","text":"<pre><code># Core dependencies\npip install typing_extensions&gt;=4.0\n\n# Flask support\npip install flask[async]&gt;=3.0\n\n# SQLAlchemy support\npip install sqlalchemy&gt;=2.0 aiosqlite greenlet\n\n# Performance optimization\npip install orjson&gt;=3.8\n</code></pre>"},{"location":"guides/getting-started/#what-each-option-provides","title":"What Each Option Provides","text":"<ul> <li><code>profilis</code> (core): Basic profiling with Emitter and AsyncCollector</li> <li><code>profilis[flask]</code>: Core + Flask request/response profiling</li> <li><code>profilis[sqlalchemy]</code>: Core + SQLAlchemy query profiling</li> <li><code>profilis[perf]</code>: Core + orjson for faster JSON serialization</li> <li><code>profilis[all]</code>: Everything including all frameworks and databases</li> </ul>"},{"location":"guides/getting-started/#quick-start-with-flask","title":"Quick Start with Flask","text":"<p>Here's a minimal Flask application with Profilis integration:</p> <pre><code>from flask import Flask\nfrom profilis.flask.adapter import ProfilisFlask\nfrom profilis.exporters.jsonl import JSONLExporter\nfrom profilis.core.async_collector import AsyncCollector\n\n# Setup exporter and collector\nexporter = JSONLExporter(dir=\"./logs\", rotate_bytes=1024*1024, rotate_secs=3600)\ncollector = AsyncCollector(exporter, queue_size=2048, batch_max=128, flush_interval=0.1)\n\n# Create Flask app\napp = Flask(__name__)\n\n# Integrate Profilis\nprofilis = ProfilisFlask(\n    app,\n    collector=collector,\n    exclude_routes=[\"/health\", \"/metrics\"],\n    sample=1.0  # 100% sampling\n)\n\n@app.route('/api/users')\ndef get_users():\n    return {\"users\": [\"alice\", \"bob\"]}\n\n@app.route('/health')\ndef health():\n    return {\"status\": \"ok\"}\n\nif __name__ == \"__main__\":\n    app.run(debug=True)\n</code></pre>"},{"location":"guides/getting-started/#function-profiling","title":"Function Profiling","text":"<p>Use the <code>@profile_function</code> decorator to profile specific functions:</p> <pre><code>from profilis.decorators.profile import profile_function\nfrom profilis.core.emitter import Emitter\nfrom profilis.exporters.console import ConsoleExporter\nfrom profilis.core.async_collector import AsyncCollector\n\n# Setup profiling\nexporter = ConsoleExporter(pretty=True)\ncollector = AsyncCollector(exporter, queue_size=128, flush_interval=0.2)\nemitter = Emitter(collector)\n\n@profile_function(emitter)\ndef expensive_calculation(n: int) -&gt; int:\n    \"\"\"This function will be automatically profiled.\"\"\"\n    result = sum(i * i for i in range(n))\n    return result\n\n@profile_function(emitter)\nasync def async_operation(data: list) -&gt; list:\n    \"\"\"Async functions are also supported.\"\"\"\n    processed = [item * 2 for item in data]\n    return processed\n\n# Use the profiled functions\nresult = expensive_calculation(1000)\n</code></pre>"},{"location":"guides/getting-started/#built-in-dashboard","title":"Built-in Dashboard","text":"<p>Enable the built-in dashboard for real-time monitoring:</p> <pre><code>from flask import Flask\nfrom profilis.flask.ui import make_ui_blueprint\nfrom profilis.core.stats import StatsStore\n\napp = Flask(__name__)\nstats = StatsStore()  # 15-minute rolling window\n\n# Mount the dashboard at /_profilis\nui_bp = make_ui_blueprint(stats, ui_prefix=\"/_profilis\")\napp.register_blueprint(ui_bp)\n\n# Visit http://localhost:5000/_profilis to see the dashboard\n</code></pre>"},{"location":"guides/getting-started/#manual-event-emission","title":"Manual Event Emission","text":"<p>For custom instrumentation, use the Emitter directly:</p> <pre><code>from profilis.core.emitter import Emitter\nfrom profilis.exporters.jsonl import JSONLExporter\nfrom profilis.core.async_collector import AsyncCollector\nfrom profilis.runtime import use_span, span_id\n\n# Setup\nexporter = JSONLExporter(dir=\"./logs\")\ncollector = AsyncCollector(exporter)\nemitter = Emitter(collector)\n\n# Create a trace context\nwith use_span(trace_id=span_id()):\n    # Emit custom events\n    emitter.emit_req(\"/api/custom\", 200, dur_ns=15000000)  # 15ms\n    emitter.emit_fn(\"custom_function\", dur_ns=5000000)      # 5ms\n    emitter.emit_db(\"SELECT * FROM users\", dur_ns=8000000, rows=100)\n\n# Close collector to flush remaining events\ncollector.close()\n</code></pre>"},{"location":"guides/getting-started/#whats-available-in-v010","title":"What's Available in v0.1.0","text":""},{"location":"guides/getting-started/#core-components","title":"Core Components","text":"<ul> <li>AsyncCollector: Non-blocking event collection with configurable batching</li> <li>Emitter: High-performance event creation and emission</li> <li>Runtime Context: Distributed tracing with trace/span ID management</li> </ul>"},{"location":"guides/getting-started/#framework-support","title":"Framework Support","text":"<ul> <li>Flask: Automatic request/response profiling with hooks</li> <li>SQLAlchemy: Query performance monitoring and instrumentation</li> </ul>"},{"location":"guides/getting-started/#exporters","title":"Exporters","text":"<ul> <li>JSONL: Rotating log files with configurable retention</li> <li>Console: Pretty-printed output for development</li> </ul>"},{"location":"guides/getting-started/#ui","title":"UI","text":"<ul> <li>Built-in Dashboard: Real-time metrics, error tracking, and performance visualization</li> </ul>"},{"location":"guides/getting-started/#decorators","title":"Decorators","text":"<ul> <li>@profile_function: Automatic timing for sync and async functions</li> </ul>"},{"location":"guides/getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Configuration - Learn about tuning and customization</li> <li>Framework Adapters - Explore Flask, FastAPI, and Sanic integration</li> <li>Database Support - Understand SQLAlchemy and other database integrations</li> <li>Exporters - Configure different output formats</li> <li>Architecture - Learn about the system design</li> </ul>"},{"location":"guides/installation/","title":"Installation Guide","text":"<p>This guide covers all the different ways to install Profilis and what each installation option provides.</p>"},{"location":"guides/installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python: 3.9 or higher</li> <li>pip: Latest version recommended</li> <li>Virtual Environment: Recommended for isolation</li> </ul>"},{"location":"guides/installation/#installation-methods","title":"Installation Methods","text":""},{"location":"guides/installation/#method-1-using-pip-with-extras-recommended","title":"Method 1: Using pip with extras (Recommended)","text":"<p>This is the most flexible and recommended approach:</p> <pre><code># Core package only\npip install profilis\n\n# With Flask support\npip install profilis[flask]\n\n# With database support\npip install profilis[flask,sqlalchemy]\n\n# With all integrations\npip install profilis[all]\n</code></pre> <p>Available Extras: - <code>flask</code>: Flask framework integration - <code>fastapi</code>: FastAPI framework integration (planned for v0.3.0) - <code>sanic</code>: Sanic framework integration (planned for v0.3.0) - <code>sqlalchemy</code>: SQLAlchemy database instrumentation - <code>pyodbc</code>: pyodbc database instrumentation (planned for v0.2.0) - <code>mongo</code>: MongoDB integration (planned for v0.2.0) - <code>neo4j</code>: Neo4j integration (planned for v0.2.0) - <code>perf</code>: Performance optimization with orjson - <code>all</code>: All available integrations - <code>dev</code>: Development dependencies</p>"},{"location":"guides/installation/#method-2-using-requirements-files","title":"Method 2: Using requirements files","text":"<p>For users who prefer requirements files:</p> <pre><code># Minimal setup (core only)\npip install -r requirements-minimal.txt\n\n# Flask integration\npip install -r requirements-flask.txt\n\n# SQLAlchemy integration\npip install -r requirements-sqlalchemy.txt\n\n# All integrations\npip install -r requirements-all.txt\n</code></pre>"},{"location":"guides/installation/#method-3-manual-installation","title":"Method 3: Manual installation","text":"<p>For complete control over dependencies:</p> <pre><code># Core dependencies\npip install typing_extensions&gt;=4.0\n\n# Flask support\npip install flask[async]&gt;=3.0\n\n# SQLAlchemy support\npip install sqlalchemy&gt;=2.0 aiosqlite greenlet\n\n# Performance optimization\npip install orjson&gt;=3.8\n</code></pre>"},{"location":"guides/installation/#what-each-installation-provides","title":"What Each Installation Provides","text":""},{"location":"guides/installation/#core-package-pip-install-profilis","title":"Core Package (<code>pip install profilis</code>)","text":"<p>Dependencies: - <code>typing_extensions&gt;=4.0</code></p> <p>Features: - AsyncCollector for non-blocking event collection - Emitter for high-performance event creation - Runtime context management - Basic exporters (JSONL, Console) - Function profiling decorator</p> <p>Use Case: Basic profiling without framework integration</p>"},{"location":"guides/installation/#flask-integration-pip-install-profilisflask","title":"Flask Integration (<code>pip install profilis[flask]</code>)","text":"<p>Dependencies: - Core dependencies - <code>flask[async]&gt;=3.0</code></p> <p>Features: - Everything from core - Automatic Flask request/response profiling - Built-in dashboard integration - Route detection and sampling</p> <p>Use Case: Flask web applications</p>"},{"location":"guides/installation/#sqlalchemy-integration-pip-install-profilissqlalchemy","title":"SQLAlchemy Integration (<code>pip install profilis[sqlalchemy]</code>)","text":"<p>Dependencies: - Core dependencies - <code>sqlalchemy&gt;=2.0</code> - <code>aiosqlite</code> - <code>greenlet</code></p> <p>Features: - Everything from core - Automatic SQL query profiling - Query redaction for security - Performance metrics</p> <p>Use Case: Applications using SQLAlchemy</p>"},{"location":"guides/installation/#performance-optimization-pip-install-profilisperf","title":"Performance Optimization (<code>pip install profilis[perf]</code>)","text":"<p>Dependencies: - Core dependencies - <code>orjson&gt;=3.8</code></p> <p>Features: - Everything from core - Faster JSON serialization - Reduced memory usage - Better performance for high-throughput applications</p> <p>Use Case: Production applications with high event volumes</p>"},{"location":"guides/installation/#all-integrations-pip-install-profilisall","title":"All Integrations (<code>pip install profilis[all]</code>)","text":"<p>Dependencies: - All framework integrations - All database integrations - Performance optimizations</p> <p>Features: - Complete feature set - All available integrations - Maximum performance</p> <p>Use Case: Applications using multiple frameworks/databases</p>"},{"location":"guides/installation/#development-installation","title":"Development Installation","text":"<p>For contributors and developers:</p> <pre><code># Clone the repository\ngit clone https://github.com/ankan97dutta/profilis.git\ncd profilis\n\n# Install in editable mode with development dependencies\npip install -e \".[dev]\"\n\n# Or use the requirements file\npip install -r requirements-dev.txt\n</code></pre>"},{"location":"guides/installation/#virtual-environment-setup","title":"Virtual Environment Setup","text":"<p>Recommended approach:</p> <pre><code># Create virtual environment\npython -m venv profilis-env\n\n# Activate virtual environment\n# On Windows:\nprofilis-env\\Scripts\\activate\n# On macOS/Linux:\nsource profilis-env/bin/activate\n\n# Install Profilis\npip install profilis[flask,sqlalchemy]\n</code></pre>"},{"location":"guides/installation/#production-installation","title":"Production Installation","text":"<p>For production deployments:</p> <pre><code># Install with specific versions for stability\npip install profilis[flask,sqlalchemy]==0.1.0\n\n# Or use requirements file with pinned versions\npip install -r requirements-production.txt\n</code></pre>"},{"location":"guides/installation/#troubleshooting-installation","title":"Troubleshooting Installation","text":""},{"location":"guides/installation/#common-issues","title":"Common Issues","text":"<ol> <li> <p>Import Errors <pre><code># Ensure core dependencies are installed\npip install typing_extensions&gt;=4.0\n</code></pre></p> </li> <li> <p>Framework Integration Not Working <pre><code># Check if framework dependencies are installed\npip list | grep flask\npip list | grep sqlalchemy\n</code></pre></p> </li> <li> <p>Performance Issues <pre><code># Install performance optimizations\npip install profilis[perf]\n</code></pre></p> </li> <li> <p>Version Conflicts <pre><code># Use virtual environment\npython -m venv profilis-env\nsource profilis-env/bin/activate\npip install profilis[flask,sqlalchemy]\n</code></pre></p> </li> </ol>"},{"location":"guides/installation/#dependency-resolution","title":"Dependency Resolution","text":"<p>If you encounter dependency conflicts:</p> <pre><code># Check current environment\npip list\n\n# Install with --force-reinstall if needed\npip install --force-reinstall profilis[flask]\n\n# Or use pip-tools for dependency resolution\npip install pip-tools\npip-compile requirements-flask.txt\npip install -r requirements-flask.txt\n</code></pre>"},{"location":"guides/installation/#platform-specific-notes","title":"Platform-Specific Notes","text":""},{"location":"guides/installation/#windows","title":"Windows","text":"<ul> <li>Ensure Visual C++ build tools are installed for some dependencies</li> <li>Use <code>py</code> instead of <code>python</code> if you have multiple Python versions</li> </ul>"},{"location":"guides/installation/#macos","title":"macOS","text":"<ul> <li>Use Homebrew Python for better dependency management</li> <li>Some dependencies may require Xcode command line tools</li> </ul>"},{"location":"guides/installation/#linux","title":"Linux","text":"<ul> <li>Install development headers: <code>sudo apt-get install python3-dev</code></li> <li>For pyodbc: <code>sudo apt-get install unixodbc-dev</code></li> </ul>"},{"location":"guides/installation/#next-steps","title":"Next Steps","text":"<p>After installation:</p> <ol> <li>Getting Started - Quick setup and basic usage</li> <li>Configuration - Tuning and customization</li> <li>Framework Adapters - Framework-specific integration</li> <li>Database Support - Database instrumentation</li> <li>Exporters - Output configuration</li> </ol>"},{"location":"meta/code-of-conduct/","title":"Code of Conduct","text":"<p>Be respectful. Harassment or discrimination is not tolerated.</p>"},{"location":"meta/contributing/","title":"Contributing","text":"<p>See CONTRIBUTING.md in repo root. Summary: - Branch: trunk\u2011based (<code>feat/*</code>, <code>fix/*</code>) - Conventional Commits - <code>ruff</code>, <code>mypy</code>, <code>pytest</code> must pass</p>"},{"location":"meta/development-guidelines/","title":"Development guidelines","text":"<ul> <li>Trunk\u2011based; squash merges</li> <li>Small PRs; tests + docs required</li> <li>Code style: ruff + black; mypy strict</li> <li>Perf\u2011sensitive changes include benchmarks</li> </ul>"},{"location":"overview/problem-statement/","title":"Problem statement","text":"<p>APIs in modern stacks get slow without clear visibility. Tooling is fragmented or heavy. Profilis provides a drop\u2011in, production\u2011safe profiler with microsecond\u2011level overhead.</p>"},{"location":"overview/roadmap/","title":"Roadmap","text":"<p>See GitHub Project: Profilis \u2013 v0 Roadmap.</p>"},{"location":"overview/roadmap/#version-status","title":"Version Status","text":""},{"location":"overview/roadmap/#v010-core-flask-sqlalchemy-ui-completed","title":"\u2705 v0.1.0 \u2014 Core + Flask + SQLAlchemy + UI (COMPLETED)","text":"<p>Released: September 2025</p> <p>Delivered Features: - Core Profiling Engine   - AsyncCollector with configurable batching and backpressure handling   - Emitter for high-performance event creation (\u226415\u00b5s per event)   - Runtime context management with trace/span ID support   - Non-blocking architecture with configurable queue sizes</p> <ul> <li>Flask Integration</li> <li>Automatic request/response profiling with hooks</li> <li>Configurable sampling and route exclusion</li> <li>Exception tracking and error reporting</li> <li> <p>Bytes in/out monitoring (best-effort)</p> </li> <li> <p>SQLAlchemy Instrumentation</p> </li> <li>Automatic query profiling with microsecond precision</li> <li>Query redaction for security</li> <li>Row count tracking</li> <li> <p>Async engine support</p> </li> <li> <p>Built-in Dashboard</p> </li> <li>Real-time metrics visualization</li> <li>Error tracking and display</li> <li>Performance trend analysis</li> <li> <p>15-minute rolling window statistics</p> </li> <li> <p>Exporters</p> </li> <li>JSONL exporter with automatic rotation</li> <li>Console exporter for development</li> <li> <p>Configurable file retention and naming</p> </li> <li> <p>Function Profiling</p> </li> <li>@profile_function decorator for sync/async functions</li> <li>Exception tracking and re-raising</li> <li>Nested span support</li> </ul> <p>Performance Metrics: - Event creation: \u226415\u00b5s per event - Memory overhead: ~100 bytes per event - Throughput: 100K+ events/second - Latency: Sub-millisecond collection overhead</p>"},{"location":"overview/roadmap/#v020-additional-database-support-in-progress","title":"\ud83d\udd04 v0.2.0 \u2014 Additional Database Support (IN PROGRESS)","text":"<p>Target: Q4 2025</p> <p>Planned Features: - pyodbc Integration   - Native ODBC connection profiling   - Query performance monitoring   - Connection pool metrics</p> <ul> <li>MongoDB Support</li> <li>PyMongo and Motor integration</li> <li>Query execution time tracking</li> <li> <p>Collection and operation profiling</p> </li> <li> <p>Neo4j Integration</p> </li> <li>Cypher query profiling</li> <li>Graph traversal metrics</li> <li>Connection pool monitoring</li> </ul> <p>Enhancements: - Database connection health monitoring - Query pattern analysis - Performance regression detection</p>"},{"location":"overview/roadmap/#v030-asgi-framework-support-planned","title":"\ud83d\udd04 v0.3.0 \u2014 ASGI Framework Support (PLANNED)","text":"<p>Target: Q4 2025</p> <p>Planned Features: - FastAPI Integration   - Native ASGI middleware   - Automatic request/response profiling   - OpenAPI integration for route detection</p> <ul> <li>Sanic Support</li> <li>Sanic-specific optimizations</li> <li>Async request handling</li> <li> <p>Performance monitoring</p> </li> <li> <p>ASGI Standard</p> </li> <li>Generic ASGI middleware</li> <li>Framework-agnostic profiling</li> <li>WebSocket support</li> </ul> <p>Enhancements: - Improved async performance - Better error handling for async contexts - WebSocket profiling</p>"},{"location":"overview/roadmap/#v040-advanced-features-resilience-planned","title":"\ud83d\udd04 v0.4.0 \u2014 Advanced Features &amp; Resilience (PLANNED)","text":"<p>Target: Q4 2025</p> <p>Planned Features: - Advanced Sampling   - Adaptive sampling based on load   - Route-specific sampling rules   - Intelligent sampling strategies</p> <ul> <li>Prometheus Integration</li> <li>Native Prometheus metrics</li> <li>Custom metric definitions</li> <li> <p>Grafana dashboard templates</p> </li> <li> <p>Resilience Features</p> </li> <li>Circuit breaker patterns</li> <li>Graceful degradation</li> <li>Self-healing capabilities</li> </ul> <p>Enhancements: - Better error handling - Performance optimization - Production hardening</p>"},{"location":"overview/roadmap/#v100-production-ready-planned","title":"\ud83d\udd04 v1.0.0 \u2014 Production Ready (PLANNED)","text":"<p>Target: Q4 2025</p> <p>Planned Features: - Comprehensive Benchmarks   - Performance regression testing   - Load testing scenarios   - Comparison with alternatives</p> <ul> <li>Production Documentation</li> <li>Deployment guides</li> <li>Monitoring best practices</li> <li> <p>Troubleshooting guides</p> </li> <li> <p>Enterprise Features</p> </li> <li>Multi-tenant support</li> <li>Advanced security features</li> <li>Compliance documentation</li> </ul> <p>Enhancements: - Production validation - Community feedback integration - Long-term support commitment</p>"},{"location":"overview/roadmap/#development-priorities","title":"Development Priorities","text":""},{"location":"overview/roadmap/#immediate-v010-v020","title":"Immediate (v0.1.0 \u2192 v0.2.0)","text":"<ol> <li>Database Integrations</li> <li>Complete pyodbc instrumentation</li> <li>Implement MongoDB profiling</li> <li> <p>Add Neo4j support</p> </li> <li> <p>Performance Optimization</p> </li> <li>Optimize AsyncCollector performance</li> <li>Reduce memory overhead</li> <li> <p>Improve batching efficiency</p> </li> <li> <p>Testing &amp; Quality</p> </li> <li>Expand test coverage</li> <li>Performance benchmarking</li> <li>Integration testing</li> </ol>"},{"location":"overview/roadmap/#short-term-v020-v030","title":"Short-term (v0.2.0 \u2192 v0.3.0)","text":"<ol> <li>ASGI Support</li> <li>FastAPI middleware development</li> <li>Sanic integration</li> <li> <p>Generic ASGI support</p> </li> <li> <p>Enhanced Exporters</p> </li> <li>Prometheus exporter</li> <li>OTLP exporter</li> <li> <p>Custom exporter framework</p> </li> <li> <p>Advanced Features</p> </li> <li>Distributed tracing</li> <li>Correlation IDs</li> <li>Advanced sampling</li> </ol>"},{"location":"overview/roadmap/#long-term-v030-v100","title":"Long-term (v0.3.0 \u2192 v1.0.0)","text":"<ol> <li>Production Features</li> <li>High availability</li> <li>Scalability improvements</li> <li> <p>Enterprise features</p> </li> <li> <p>Ecosystem Integration</p> </li> <li>Third-party integrations</li> <li>Plugin system</li> <li> <p>Community contributions</p> </li> <li> <p>Documentation &amp; Support</p> </li> <li>Comprehensive guides</li> <li>Video tutorials</li> <li>Community support</li> </ol>"},{"location":"overview/roadmap/#contributing-to-the-roadmap","title":"Contributing to the Roadmap","text":""},{"location":"overview/roadmap/#how-to-contribute","title":"How to Contribute","text":"<ol> <li>Feature Requests: Open GitHub issues for new features</li> <li>Implementation: Submit pull requests for planned features</li> <li>Testing: Help test and validate new functionality</li> <li>Documentation: Improve and expand documentation</li> <li>Feedback: Share your experience and use cases</li> </ol>"},{"location":"overview/roadmap/#development-guidelines","title":"Development Guidelines","text":"<ul> <li>Follow the established code patterns</li> <li>Include comprehensive tests</li> <li>Update documentation for new features</li> <li>Consider backward compatibility</li> <li>Focus on performance and reliability</li> </ul>"},{"location":"overview/roadmap/#community-input","title":"Community Input","text":"<ul> <li>GitHub Discussions: Share ideas and feedback</li> <li>Issue Tracking: Report bugs and request features</li> <li>Pull Requests: Contribute code improvements</li> <li>Documentation: Help improve guides and examples</li> </ul>"},{"location":"overview/roadmap/#release-schedule","title":"Release Schedule","text":""},{"location":"overview/roadmap/#release-cadence","title":"Release Cadence","text":"<ul> <li>Minor Releases: Every 3-4 months</li> <li>Patch Releases: As needed for bug fixes</li> <li>Major Releases: Annual (v1.0.0)</li> </ul>"},{"location":"overview/roadmap/#release-process","title":"Release Process","text":"<ol> <li>Feature Freeze: 2 weeks before release</li> <li>Testing Phase: 1 week of intensive testing</li> <li>Release Candidate: 1 week before final release</li> <li>Production Release: Tagged and documented</li> </ol>"},{"location":"overview/roadmap/#support-policy","title":"Support Policy","text":"<ul> <li>Current Release: Full support and bug fixes</li> <li>Previous Release: Security fixes only</li> <li>Older Releases: Community support only</li> </ul>"},{"location":"overview/roadmap/#success-metrics","title":"Success Metrics","text":""},{"location":"overview/roadmap/#technical-metrics","title":"Technical Metrics","text":"<ul> <li>Performance: Maintain \u226415\u00b5s event creation overhead</li> <li>Reliability: 99.9% uptime for profiling systems</li> <li>Scalability: Support 1M+ events/second</li> <li>Memory: &lt;1MB overhead per 10K events</li> </ul>"},{"location":"overview/roadmap/#adoption-metrics","title":"Adoption Metrics","text":"<ul> <li>Downloads: Track PyPI download statistics</li> <li>GitHub Stars: Monitor community interest</li> <li>Issues &amp; PRs: Measure community engagement</li> <li>Documentation: Track documentation usage</li> </ul>"},{"location":"overview/roadmap/#quality-metrics","title":"Quality Metrics","text":"<ul> <li>Test Coverage: Maintain &gt;90% test coverage</li> <li>Performance Regression: Zero performance regressions</li> <li>Security: Regular security audits</li> <li>Documentation: Comprehensive and up-to-date guides</li> </ul>"},{"location":"ui/ui/","title":"Built-in UI Dashboard","text":"<p>Profilis includes a real-time dashboard for monitoring application performance, errors, and metrics.</p>"},{"location":"ui/ui/#quick-start","title":"Quick Start","text":"<pre><code>from flask import Flask\nfrom profilis.flask.ui import make_ui_blueprint\nfrom profilis.core.stats import StatsStore\n\napp = Flask(__name__)\nstats = StatsStore()  # 15-minute rolling window\n\n# Mount the dashboard at /_profilis\nui_bp = make_ui_blueprint(stats, ui_prefix=\"/_profilis\")\napp.register_blueprint(ui_bp)\n\n# Visit http://localhost:5000/_profilis for the dashboard\n</code></pre>"},{"location":"ui/ui/#features","title":"Features","text":""},{"location":"ui/ui/#real-time-metrics","title":"Real-time Metrics","text":"<ul> <li>Request Latency: P50, P95, P99 percentiles</li> <li>Throughput: Requests per second</li> <li>Error Rates: Error percentage by route</li> <li>Response Times: Distribution of response times</li> </ul>"},{"location":"ui/ui/#error-tracking","title":"Error Tracking","text":"<ul> <li>Recent Errors: Last 100 errors with details</li> <li>Exception Types: Breakdown by exception class</li> <li>Route Analysis: Error rates per endpoint</li> <li>Stack Traces: Full error context when available</li> </ul>"},{"location":"ui/ui/#performance-monitoring","title":"Performance Monitoring","text":"<ul> <li>Database Queries: Query performance metrics</li> <li>Function Calls: Profiled function timing</li> <li>Resource Usage: Memory and CPU utilization</li> <li>Trend Analysis: Performance over time</li> </ul>"},{"location":"ui/ui/#dashboard-components","title":"Dashboard Components","text":""},{"location":"ui/ui/#main-dashboard","title":"Main Dashboard","text":"<p>The primary dashboard provides an overview of application health:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Profilis Dashboard                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Requests/sec: 1,234  \u2502  Avg Latency: 45ms  \u2502  Errors: 2% \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  [Latency Chart]        \u2502  [Throughput Chart]              \u2502\n\u2502  P50: 25ms             \u2502  P95: 120ms                      \u2502\n\u2502  P99: 250ms            \u2502  P99.9: 500ms                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  [Error Rate Chart]     \u2502  [Route Performance]             \u2502\n\u2502  Recent Errors: 5      \u2502  Top Routes by Latency           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ui/ui/#metrics-api","title":"Metrics API","text":"<p>Programmatic access to dashboard data:</p> <pre><code># Get metrics as JSON\nGET /_profilis/metrics.json\n\n# Response format\n{\n  \"requests\": {\n    \"total\": 1234,\n    \"errors\": 25,\n    \"error_rate\": 0.02,\n    \"latency\": {\n      \"p50\": 25000000,    # 25ms in nanoseconds\n      \"p95\": 120000000,   # 120ms in nanoseconds\n      \"p99\": 250000000    # 250ms in nanoseconds\n    }\n  },\n  \"routes\": {\n    \"/api/users\": {\n      \"count\": 456,\n      \"errors\": 5,\n      \"avg_latency\": 30000000\n    }\n  },\n  \"errors\": [\n    {\n      \"ts_ns\": 1703123456789000000,\n      \"route\": \"/api/users\",\n      \"status\": 500,\n      \"exception_type\": \"ValueError\",\n      \"exception_value\": \"Invalid user ID\"\n    }\n  ]\n}\n</code></pre>"},{"location":"ui/ui/#configuration","title":"Configuration","text":""},{"location":"ui/ui/#basic-setup","title":"Basic Setup","text":"<pre><code>from profilis.flask.ui import make_ui_blueprint\nfrom profilis.core.stats import StatsStore\n\n# Create stats store\nstats = StatsStore(\n    window_minutes=15,      # Rolling window size\n    max_errors=100          # Maximum errors to track\n)\n\n# Create UI blueprint\nui_bp = make_ui_blueprint(\n    stats,\n    ui_prefix=\"/_profilis\"  # URL prefix\n)\n</code></pre>"},{"location":"ui/ui/#advanced-configuration","title":"Advanced Configuration","text":"<pre><code># Production configuration with authentication\nui_bp = make_ui_blueprint(\n    stats,\n    ui_prefix=\"/_profilis\",\n    ui_auth_token=\"secret123\",  # Bearer token authentication\n    ui_title=\"Production Dashboard\",\n    ui_theme=\"dark\"             # Dark theme\n)\n\n# Custom configuration\nui_bp = make_ui_blueprint(\n    stats,\n    ui_prefix=\"/monitoring\",\n    ui_auth_token=\"prod-token-456\",\n    ui_title=\"MyApp Monitoring\",\n    ui_theme=\"light\",\n    ui_refresh_interval=5000    # 5 second refresh\n)\n</code></pre>"},{"location":"ui/ui/#statsstore-configuration","title":"StatsStore Configuration","text":"<pre><code># Configure stats collection\nstats = StatsStore(\n    window_minutes=30,          # 30-minute rolling window\n    max_errors=500,             # Track up to 500 errors\n    max_routes=1000,            # Track up to 1000 routes\n    precision_ns=1000000        # 1ms precision\n)\n</code></pre>"},{"location":"ui/ui/#integration-patterns","title":"Integration Patterns","text":""},{"location":"ui/ui/#with-flask-adapter","title":"With Flask Adapter","text":"<pre><code>from flask import Flask\nfrom profilis.flask.adapter import ProfilisFlask\nfrom profilis.flask.ui import make_ui_blueprint\nfrom profilis.core.stats import StatsStore\n\napp = Flask(__name__)\n\n# Setup Profilis profiling\nexporter = JSONLExporter(dir=\"./logs\")\ncollector = AsyncCollector(exporter)\nprofilis = ProfilisFlask(app, collector=collector)\n\n# Add dashboard\nstats = StatsStore()\nui_bp = make_ui_blueprint(stats, ui_prefix=\"/_profilis\")\napp.register_blueprint(ui_bp)\n\n# Now both profiling and dashboard are available\n</code></pre>"},{"location":"ui/ui/#with-custom-stats","title":"With Custom Stats","text":"<pre><code>from profilis.core.stats import StatsStore\nfrom profilis.core.emitter import Emitter\n\n# Custom stats collection\nstats = StatsStore()\nemitter = Emitter(collector)\n\n# Record custom metrics\ndef record_custom_metric(name: str, value: float):\n    stats.record_custom(name, value)\n\n# Use in your application\n@app.route('/api/process')\ndef process_data():\n    start_time = time.time_ns()\n\n    # Process data...\n    result = expensive_operation()\n\n    # Record custom metric\n    duration = time.time_ns() - start_time\n    record_custom_metric(\"process_duration\", duration)\n\n    return result\n</code></pre>"},{"location":"ui/ui/#dashboard-features","title":"Dashboard Features","text":""},{"location":"ui/ui/#real-time-updates","title":"Real-time Updates","text":"<p>The dashboard automatically refreshes to show current metrics:</p> <ul> <li>Auto-refresh: Configurable refresh intervals</li> <li>Live Updates: Real-time metric updates</li> <li>Historical Data: Rolling window statistics</li> <li>Trend Analysis: Performance over time</li> </ul>"},{"location":"ui/ui/#interactive-charts","title":"Interactive Charts","text":"<p>Visual representation of performance data:</p> <ul> <li>Latency Distribution: Histogram of response times</li> <li>Throughput Trends: Requests per second over time</li> <li>Error Patterns: Error rates and types</li> <li>Route Performance: Endpoint-specific metrics</li> </ul>"},{"location":"ui/ui/#error-analysis","title":"Error Analysis","text":"<p>Comprehensive error tracking and analysis:</p> <ul> <li>Error Details: Full exception information</li> <li>Route Correlation: Errors by endpoint</li> <li>Time Analysis: When errors occur</li> <li>Pattern Recognition: Common error types</li> </ul>"},{"location":"ui/ui/#security-and-access-control","title":"Security and Access Control","text":""},{"location":"ui/ui/#authentication","title":"Authentication","text":"<pre><code># Enable bearer token authentication\nui_bp = make_ui_blueprint(\n    stats,\n    ui_prefix=\"/_profilis\",\n    ui_auth_token=\"your-secret-token\"\n)\n\n# Access with Authorization header\n# Authorization: Bearer your-secret-token\n</code></pre>"},{"location":"ui/ui/#access-control","title":"Access Control","text":"<pre><code># Custom authentication middleware\nfrom functools import wraps\nfrom flask import request, abort\n\ndef require_auth(f):\n    @wraps(f)\n    def decorated_function(*args, **kwargs):\n        token = request.headers.get('Authorization')\n        if not token or token != 'Bearer your-token':\n            abort(401)\n        return f(*args, **kwargs)\n    return decorated_function\n\n# Apply to dashboard routes\n@app.route('/_profilis')\n@require_auth\ndef dashboard():\n    return render_template('dashboard.html')\n</code></pre>"},{"location":"ui/ui/#production-security","title":"Production Security","text":"<pre><code># Production configuration\nui_bp = make_ui_blueprint(\n    stats,\n    ui_prefix=\"/_profilis\",\n    ui_auth_token=os.environ.get('PROFILIS_TOKEN'),\n    ui_https_only=True,\n    ui_cors_origins=['https://yourdomain.com']\n)\n</code></pre>"},{"location":"ui/ui/#customization","title":"Customization","text":""},{"location":"ui/ui/#custom-themes","title":"Custom Themes","text":"<pre><code># Custom CSS styling\ncustom_css = \"\"\"\n.dashboard-header {\n    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n    color: white;\n}\n\n.metric-card {\n    border-radius: 10px;\n    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n}\n\"\"\"\n\nui_bp = make_ui_blueprint(\n    stats,\n    ui_prefix=\"/_profilis\",\n    ui_custom_css=custom_css\n)\n</code></pre>"},{"location":"ui/ui/#custom-metrics","title":"Custom Metrics","text":"<pre><code># Extend StatsStore for custom metrics\nclass CustomStatsStore(StatsStore):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.custom_metrics = {}\n\n    def record_custom(self, name: str, value: float):\n        \"\"\"Record custom metric\"\"\"\n        if name not in self.custom_metrics:\n            self.custom_metrics[name] = []\n\n        self.custom_metrics[name].append({\n            'ts_ns': time.time_ns(),\n            'value': value\n        })\n\n    def get_custom_metrics(self):\n        \"\"\"Get custom metrics summary\"\"\"\n        summary = {}\n        for name, values in self.custom_metrics.items():\n            if values:\n                summary[name] = {\n                    'count': len(values),\n                    'avg': sum(v['value'] for v in values) / len(values),\n                    'min': min(v['value'] for v in values),\n                    'max': max(v['value'] for v in values)\n                }\n        return summary\n\n# Use custom stats store\ncustom_stats = CustomStatsStore()\nui_bp = make_ui_blueprint(custom_stats, ui_prefix=\"/_profilis\")\n</code></pre>"},{"location":"ui/ui/#monitoring-and-alerting","title":"Monitoring and Alerting","text":""},{"location":"ui/ui/#health-checks","title":"Health Checks","text":"<pre><code>@app.route('/_profilis/health')\ndef dashboard_health():\n    \"\"\"Check dashboard health\"\"\"\n    return {\n        \"status\": \"healthy\",\n        \"stats_store\": {\n            \"window_minutes\": stats.window_minutes,\n            \"total_requests\": stats.total_requests,\n            \"total_errors\": stats.total_errors,\n            \"error_rate\": stats.error_rate\n        },\n        \"collector\": {\n            \"queue_size\": collector.queue.qsize(),\n            \"queue_max\": collector.queue.maxsize\n        }\n    }\n</code></pre>"},{"location":"ui/ui/#integration-with-external-monitoring","title":"Integration with External Monitoring","text":"<pre><code># Prometheus metrics endpoint\n@app.route('/_profilis/metrics')\ndef prometheus_metrics():\n    \"\"\"Prometheus-formatted metrics\"\"\"\n    metrics = []\n\n    # Request metrics\n    metrics.append(f\"profilis_requests_total {stats.total_requests}\")\n    metrics.append(f\"profilis_errors_total {stats.total_errors}\")\n    metrics.append(f\"profilis_error_rate {stats.error_rate}\")\n\n    # Latency metrics\n    if stats.latency_percentiles:\n        p50 = stats.latency_percentiles.get(50, 0)\n        p95 = stats.latency_percentiles.get(95, 0)\n        p99 = stats.latency_percentiles.get(99, 0)\n\n        metrics.append(f\"profilis_latency_p50 {p50}\")\n        metrics.append(f\"profilis_latency_p95 {p95}\")\n        metrics.append(f\"profilis_latency_p99 {p99}\")\n\n    return '\\n'.join(metrics), 200, {'Content-Type': 'text/plain'}\n</code></pre>"},{"location":"ui/ui/#troubleshooting","title":"Troubleshooting","text":""},{"location":"ui/ui/#common-issues","title":"Common Issues","text":"<ol> <li>Dashboard Not Loading: Check blueprint registration and routes</li> <li>No Data Displayed: Verify StatsStore is receiving data</li> <li>Authentication Errors: Check bearer token configuration</li> <li>Performance Issues: Monitor dashboard refresh intervals</li> </ol>"},{"location":"ui/ui/#debug-mode","title":"Debug Mode","text":"<pre><code>import os\nos.environ['PROFILIS_DEBUG'] = '1'\n\n# This will enable debug logging for the dashboard\nui_bp = make_ui_blueprint(stats, ui_prefix=\"/_profilis\")\n</code></pre>"},{"location":"ui/ui/#performance-optimization","title":"Performance Optimization","text":"<pre><code># Optimize for high-traffic applications\nstats = StatsStore(\n    window_minutes=5,       # Shorter window for real-time updates\n    max_errors=50,          # Limit error storage\n    max_routes=100          # Limit route tracking\n)\n\n# Reduce refresh frequency\nui_bp = make_ui_blueprint(\n    stats,\n    ui_prefix=\"/_profilis\",\n    ui_refresh_interval=10000  # 10 second refresh\n)\n</code></pre>"},{"location":"ui/ui/#best-practices","title":"Best Practices","text":"<ol> <li>Use Appropriate Window Sizes: Balance real-time updates with memory usage</li> <li>Implement Authentication: Always secure dashboard access in production</li> <li>Monitor Dashboard Performance: Watch for dashboard impact on application</li> <li>Regular Cleanup: Monitor StatsStore memory usage</li> <li>Custom Metrics: Extend with application-specific monitoring</li> <li>Integration: Connect with existing monitoring infrastructure</li> </ol>"}]}